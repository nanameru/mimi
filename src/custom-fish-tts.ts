import { tts } from '@livekit/agents';
import { AudioFrame } from '@livekit/rtc-node';
import { Session, TTSRequest, type Backends } from 'fish-audio-sdk';
import * as fs from 'fs';
import * as path from 'path';

/**
 * Fish Audio TTS è¨­å®š
 * å…¬å¼ fish-audio-sdk ã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°åˆæˆ
 * HTTP APIã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
 * æ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã®æœ€é©åŒ–ã‚’å®Ÿè£…
 * ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: https://docs.fish.audio/api-reference/introduction
 * npm: https://www.npmjs.com/package/fish-audio-sdk
 */
export interface FishAudioTTSOptions {
  apiKey?: string;
  voiceId?: string;
  sampleRate?: number;
  numChannels?: number;
  backend?: Backends;
  chunkLength?: number;
  latency?: 'normal' | 'balanced';
}


/**
 * Fish Audio TTS å®Ÿè£…
 * HTTP APIã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
 * æ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã¨HTTP/2ã®æœ€é©åŒ–ã‚’å®Ÿè£…
 */
export class FishAudioTTS extends tts.TTS {
  label = 'fish-audio-tts';
  public apiKey: string;
  public voiceId: string;
  public backend: Backends;
  public chunkLength: number;
  public latency: 'normal' | 'balanced';
  public httpSession: Session;

  constructor(options: FishAudioTTSOptions = {}) {
    const sampleRate = options.sampleRate || 44100;
    const numChannels = options.numChannels || 1;
    // TTS capabilities ã‚’è¨­å®šï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
    super(sampleRate, numChannels, {
      streaming: true,
    });
    this.apiKey = options.apiKey || process.env.FISH_AUDIO_API_KEY || '';
    this.voiceId = options.voiceId || process.env.FISH_AUDIO_VOICE_ID || '';
    this.backend = options.backend || 'speech-1.5';
    this.chunkLength = options.chunkLength || 100;
    this.latency = options.latency || 'balanced';
    if (!this.apiKey) {
      throw new Error('FISH_AUDIO_API_KEY is required');
    }
    // HTTP Session ã‚’åˆæœŸåŒ–ï¼ˆæ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–ï¼‰
    // fish-audio-sdkã®Sessionã‚¯ãƒ©ã‚¹ã¯æ—¢ã«keepAliveã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€
    // åŸºæœ¬çš„ãªæ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã™
    // ã‚ˆã‚Šè©³ç´°ãªæœ€é©åŒ–ï¼ˆmaxSockets, maxFreeSocketsãªã©ï¼‰ãŒå¿…è¦ãªå ´åˆã¯ã€
    // fish-audio-sdkã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
    // HTTP/2ã®ã‚µãƒãƒ¼ãƒˆã«ã¤ã„ã¦ã¯ã€Fish Audio APIãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‹ç¢ºèªãŒå¿…è¦ã§ã™
    this.httpSession = new Session(this.apiKey);
    console.log(
      `[FishAudioTTS] Initialized with HTTP API: backend=${this.backend}, voiceId=${this.voiceId ? 'set' : 'not set'}, sampleRate=${sampleRate}Hz, channels=${numChannels}`,
    );
    console.log('[FishAudioTTS] Connection pooling: keepAlive=true (fish-audio-sdk default)');
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’åˆæˆï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
   */
  synthesize(text: string): tts.ChunkedStream {
    console.log(`[FishAudioTTS] Synthesizing text (length=${text.length})`);
    return new FishAudioChunkedStream(text, this);
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° TTS
   */
  stream(): tts.SynthesizeStream {
    console.log('[FishAudioTTS] Creating streaming session');
    return new FishAudioSynthesizeStream(this);
  }

  /**
   * ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
   */
  async close(): Promise<void> {
    this.httpSession.close();
    console.log('[FishAudioTTS] HTTP session closed');
  }
}

/**
 * Fish Audio ãƒãƒ£ãƒ³ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆæˆç”¨ï¼‰
 */
class FishAudioChunkedStream extends tts.ChunkedStream {
  label = 'fish-audio-chunked-stream';
  private text: string;
  private ttsInstance: FishAudioTTS;

  constructor(text: string, ttsInstance: FishAudioTTS) {
    super(text, ttsInstance);
    this.text = text;
    this.ttsInstance = ttsInstance;
  }

  async run() {
    try {
      console.log('[FishAudioTTS] Starting non-streaming synthesis');
      // TTSRequest ã‚’ä½œæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã‚‹ï¼‰
      const request = new TTSRequest(this.text, {
        referenceId: this.ttsInstance.voiceId,
        format: 'pcm',
        sampleRate: this.ttsInstance.sampleRate,
        chunkLength: this.ttsInstance.chunkLength,
        latency: this.ttsInstance.latency,
        normalize: true,
      });
      // HTTP APIã§éŸ³å£°ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰
      // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦modelãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
      const audioChunks: Buffer[] = [];
      let firstChunkForSynthesize = true;
      for await (const chunk of this.ttsInstance.httpSession.tts(request, {
        model: this.ttsInstance.backend,
      })) {
        // æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®å…ˆé ­ãƒã‚¤ãƒˆã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šç”¨ï¼‰
        if (firstChunkForSynthesize) {
          const firstChunkPreview = chunk.slice(0, Math.min(32, chunk.length));
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (hex): ${firstChunkPreview.toString('hex')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk length: ${chunk.length} bytes`);
          
          // MP3ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ç¢ºèª
          const firstBytes = chunk.slice(0, 4);
          const hexString = firstBytes.toString('hex').toUpperCase();
          if (hexString.startsWith('FF')) {
            console.log(`[FishAudioTTS] âš ï¸ WARNING: First bytes suggest MP3 format (${hexString}), but PCM format was requested!`);
            console.log(`[FishAudioTTS] âš ï¸ This may cause audio quality issues. MP3 decoding may be required.`);
          } else {
            console.log(`[FishAudioTTS] âœ“ First bytes suggest PCM format (${hexString})`);
            
            // PCMãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç¢ºèª
            if (chunk.length >= 2) {
              const firstSampleLE = chunk.readInt16LE(0);
              const firstSampleBE = chunk.readInt16BE(0);
              console.log(`[FishAudioTTS] ğŸ“Š First sample (Little Endian): ${firstSampleLE}`);
              console.log(`[FishAudioTTS] ğŸ“Š First sample (Big Endian): ${firstSampleBE}`);
            }
          }
          firstChunkForSynthesize = false;
        }
        audioChunks.push(chunk);
      }
      // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
      const audioBuffer = Buffer.concat(audioChunks);
      console.log(`[FishAudioTTS] Received ${audioBuffer.length} bytes of audio`);
      // LiveKit AudioFrame ã«å¤‰æ›
      const pcmData = new Int16Array(
        audioBuffer.buffer,
        audioBuffer.byteOffset,
        audioBuffer.length / 2,
      );
      const samplesPerChannel = pcmData.length / this.ttsInstance.numChannels;
      const audioFrame = new AudioFrame(
        pcmData,
        this.ttsInstance.sampleRate,
        this.ttsInstance.numChannels,
        samplesPerChannel,
      );
      const audio = {
        requestId: '',
        segmentId: 'segment-0',
        frame: audioFrame,
        final: true,
      };
      this.queue.put(audio);
      console.log('[FishAudioTTS] Synthesis completed');
    } catch (error) {
      console.error('[FishAudioTTS] Error:', error);
      throw error;
    }
  }
}

/**
 * Fish Audio ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…
 * LLM ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŸ³å£°ã«å¤‰æ›
 */
class FishAudioSynthesizeStream extends tts.SynthesizeStream {
  label = 'fish-audio-synthesize-stream';
  private ttsInstance: FishAudioTTS;

  constructor(ttsInstance: FishAudioTTS) {
    super(ttsInstance);
    this.ttsInstance = ttsInstance;
  }

  async run() {
    try {
      const sessionStartTime = Date.now();
      console.log(
        `[FishAudioTTS] [${new Date().toLocaleTimeString()}] Starting HTTP API streaming synthesis session`,
      );
      
      // LLMã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å®Œå…¨ã«å—ä¿¡
      const textBuffer: string[] = [];
      for await (const text of this.input) {
        if (text === FishAudioSynthesizeStream.FLUSH_SENTINEL) {
          // FLUSH_SENTINELãŒæ¥ãŸã‚‰ã€ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
          if (textBuffer.length > 0) {
            break; // ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦HTTP APIã«é€ä¿¡
          }
          continue;
        }
        textBuffer.push(text);
      }
      
      // ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
      const fullText = textBuffer.join('');
      console.log(
        `[FishAudioTTS] ğŸ“¤ [${new Date().toLocaleTimeString()}] Sending text to HTTP API (${fullText.length} chars): "${fullText.substring(0, 50)}..."`,
      );
      
      // HTTP APIã§éŸ³å£°ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰
      // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦modelãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
      const request = new TTSRequest(fullText, {
        referenceId: this.ttsInstance.voiceId,
        format: 'pcm',
        sampleRate: this.ttsInstance.sampleRate,
        chunkLength: this.ttsInstance.chunkLength,
        latency: this.ttsInstance.latency,
        normalize: true,
      });
      
      let segmentId = 0;
      let firstChunkReceived = false;
      let totalChunks = 0;
      let globalMaxAmplitude = 0;
      let gainFactor: number | null = null;
      const GAIN_CALIBRATION_CHUNKS = 20; // æœ€åˆã®20ãƒãƒ£ãƒ³ã‚¯ã§ã‚²ã‚¤ãƒ³ã‚’æ±ºå®š
      const MAX_GAIN_FACTOR = 100; // æœ€å¤§ã‚²ã‚¤ãƒ³å€ç‡ï¼ˆæ¥µç«¯ãªå¢—å¹…ã‚’é˜²ãï¼‰
      const MIN_AMPLITUDE_THRESHOLD = 100; // ã“ã®å€¤æœªæº€ã®å ´åˆã€å¢—å¹…ãŒå¿…è¦
      
      // ç„¡éŸ³ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚­ãƒƒãƒ—ç”¨å¤‰æ•°
      let audioStarted = false; // éŸ³å£°ãŒé–‹å§‹ã•ã‚ŒãŸã‹ã©ã†ã‹
      const SILENCE_THRESHOLD = 100; // ã“ã®å€¤æœªæº€ã¯ç„¡éŸ³ã¨ã¿ãªã™
      const MAX_SILENT_CHUNKS_BEFORE_START = 50; // éŸ³å£°é–‹å§‹å‰ã«ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹æœ€å¤§ãƒãƒ£ãƒ³ã‚¯æ•°
      
      // ãƒ‡ãƒ¼ã‚¿å½¢å¼åˆ¤å®šç”¨ã®å¤‰æ•°
      let allChunksForAnalysis: Buffer[] = [];
      const MAX_CHUNKS_FOR_ANALYSIS = 50; // æœ€åˆã®50ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ã—ã¦åˆ†æï¼ˆæ­£å¸¸ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰
      
      console.log(`[FishAudioTTS] Starting HTTP API TTS with backend: ${this.ttsInstance.backend}, voiceId: ${this.ttsInstance.voiceId || 'not set'}`);
      
      // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
      const detectAudioFormat = (data: Buffer): string => {
        if (data.length < 4) return 'UNKNOWN';
        
        const firstBytes = data.slice(0, 4);
        const hexString = firstBytes.toString('hex').toUpperCase();
        
        // MP3å½¢å¼ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        // MP3: FF FB, FF F3, FF F2, FF FA, FF E3, FF E2, FF E1, FF E0
        if (hexString.startsWith('FF')) {
          const secondByte = firstBytes[1];
          if (secondByte === 0xFB || secondByte === 0xF3 || secondByte === 0xF2 || secondByte === 0xFA ||
              secondByte === 0xE3 || secondByte === 0xE2 || secondByte === 0xE1 || secondByte === 0xE0) {
            return 'MP3';
          }
        }
        
        // WAVå½¢å¼ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        // WAV: 52 49 46 46 (RIFF) ã¾ãŸã¯ 52 49 46 46 (RIFF) + 57 41 56 45 (WAVE)
        if (data.length >= 12) {
          const riffHeader = data.slice(0, 4).toString('ascii');
          if (riffHeader === 'RIFF') {
            const waveHeader = data.slice(8, 12).toString('ascii');
            if (waveHeader === 'WAVE') {
              return 'WAV';
            }
          }
        }
        
        // Opuså½¢å¼ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        // Opus: OggS (4F 67 67 53)
        if (data.length >= 4) {
          const oggHeader = data.slice(0, 4).toString('ascii');
          if (oggHeader === 'OggS') {
            return 'OPUS';
          }
        }
        
        // PCMå½¢å¼ã®åˆ¤å®šï¼ˆãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„ç‰¹æ€§ã‹ã‚‰ï¼‰
        // PCMãƒ‡ãƒ¼ã‚¿ã¯é€šå¸¸ã€ãƒ©ãƒ³ãƒ€ãƒ ãªãƒã‚¤ãƒˆåˆ†å¸ƒã‚’æŒã¤
        // ã—ã‹ã—ã€æœ€åˆã®æ•°ãƒã‚¤ãƒˆãŒå…¨ã¦0xFFã‚„0x00ã®å ´åˆã¯ã€ä»–ã®å½¢å¼ã®å¯èƒ½æ€§ãŒã‚ã‚‹
        const first16Bytes = data.slice(0, Math.min(16, data.length));
        const uniqueBytes = new Set(Array.from(first16Bytes)).size;
        
        // å…¨ã¦åŒã˜ãƒã‚¤ãƒˆå€¤ï¼ˆ0xFFã‚„0x00ãªã©ï¼‰ã®å ´åˆã¯ã€PCMã§ã¯ãªã„å¯èƒ½æ€§ãŒé«˜ã„
        if (uniqueBytes === 1) {
          return 'SUSPICIOUS (all same bytes)';
        }
        
        // ãƒã‚¤ãƒˆã®åˆ†å¸ƒã‚’ç¢ºèªï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®ç°¡å˜ãªãƒã‚§ãƒƒã‚¯ï¼‰
        const byteCounts = new Array(256).fill(0);
        const sampleSize = Math.min(256, data.length);
        for (let i = 0; i < sampleSize; i++) {
          byteCounts[data[i]!]++;
        }
        
        // ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒä½ã„å ´åˆï¼ˆç‰¹å®šã®ãƒã‚¤ãƒˆå€¤ã«åã£ã¦ã„ã‚‹ï¼‰ã€åœ§ç¸®å½¢å¼ã®å¯èƒ½æ€§
        const entropy = byteCounts.reduce((sum, count) => {
          if (count === 0) return sum;
          const p = count / sampleSize;
          return sum - p * Math.log2(p);
        }, 0);
        
        // ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒä½ã„å ´åˆï¼ˆ< 5.0ï¼‰ã€åœ§ç¸®å½¢å¼ã®å¯èƒ½æ€§
        if (entropy < 5.0 && entropy > 0) {
          return `SUSPICIOUS (low entropy: ${entropy.toFixed(2)})`;
        }
        
        // ãƒ‡ãƒ¼ã‚¿ãŒ2ãƒã‚¤ãƒˆã®å€æ•°ã§ã€16-bit PCMã¨ã—ã¦è§£é‡ˆå¯èƒ½ãªå ´åˆ
        if (data.length % 2 === 0) {
          // ã‚µãƒ³ãƒ—ãƒ«å€¤ã‚’ç¢ºèªã—ã¦ã€Int16ã®ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
          const samples = new Int16Array(data.buffer, data.byteOffset, Math.min(100, data.length / 2));
          const minSample = Math.min(...Array.from(samples));
          const maxSample = Math.max(...Array.from(samples));
          
          // Int16ã®ç¯„å›²å†…ã§ã‚ã‚Œã°ã€PCMã®å¯èƒ½æ€§ãŒé«˜ã„
          if (minSample >= -32768 && maxSample <= 32767) {
            return 'PCM (16-bit, Int16 range)';
          }
        }
        
        return 'UNKNOWN';
      };
      
      // HTTP APIã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
      for await (const audioChunk of this.ttsInstance.httpSession.tts(request, {
        model: this.ttsInstance.backend,
      })) {
        totalChunks++;
        
        // æœ€åˆã®æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ã—ã¦åˆ†æï¼ˆæ­£å¸¸ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰
        if (totalChunks <= MAX_CHUNKS_FOR_ANALYSIS) {
          allChunksForAnalysis.push(Buffer.from(audioChunk));
        }
        
        // æœ€åˆã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å—ä¿¡æ™‚ã®ãƒ­ã‚°
        if (!firstChunkReceived) {
          const firstChunkTime = Date.now() - sessionStartTime;
          console.log(
            `[FishAudioTTS] â±ï¸ First audio chunk received after ${firstChunkTime}ms`,
          );
          // æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®å…ˆé ­ãƒã‚¤ãƒˆã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šç”¨ï¼‰
          const firstChunkPreview = audioChunk.slice(0, Math.min(32, audioChunk.length));
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (hex): ${firstChunkPreview.toString('hex')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (decimal): ${Array.from(firstChunkPreview).join(', ')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk length: ${audioChunk.length} bytes`);
          
          // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è©³ç´°ã«åˆ¤å®š
          const detectedFormat = detectAudioFormat(audioChunk);
          console.log(`[FishAudioTTS] ğŸ” Detected audio format: ${detectedFormat}`);
          
          // MP3ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ç¢ºèªï¼ˆFF FB, FF F3, FF F2, FF FAãªã©ï¼‰
          const firstBytes = audioChunk.slice(0, 4);
          const hexString = firstBytes.toString('hex').toUpperCase();
          if (hexString.startsWith('FF')) {
            console.log(`[FishAudioTTS] âš ï¸ WARNING: First bytes suggest MP3 format (${hexString}), but PCM format was requested!`);
            console.log(`[FishAudioTTS] âš ï¸ This may cause audio quality issues. MP3 decoding may be required.`);
          } else {
            console.log(`[FishAudioTTS] âœ“ First bytes suggest PCM format (${hexString})`);
          }
          
          // PCMãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’ç¢ºèª
          if (audioChunk.length >= 2) {
            const sampleCount = audioChunk.length / 2;
            console.log(`[FishAudioTTS] ğŸ“Š Estimated sample count: ${sampleCount} (assuming 16-bit PCM)`);
            console.log(`[FishAudioTTS] ğŸ“Š Estimated duration: ${(sampleCount / this.ttsInstance.sampleRate * 1000).toFixed(2)}ms`);
            
            // å®Ÿéš›ã®PCMãƒ‡ãƒ¼ã‚¿ã®å€¤ã‚’ç¢ºèªï¼ˆæœ€åˆã®10ã‚µãƒ³ãƒ—ãƒ«ï¼‰
            const pcmSamples = new Int16Array(
              audioChunk.buffer,
              audioChunk.byteOffset,
              Math.min(10, audioChunk.length / 2),
            );
            console.log(`[FishAudioTTS] ğŸ“Š First 10 PCM samples (Int16): [${Array.from(pcmSamples).join(', ')}]`);
            
            // ãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã¨ãƒ“ãƒƒã‚°ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã®ä¸¡æ–¹ã‚’ç¢ºèª
            const firstSampleLE = audioChunk.readInt16LE(0);
            const firstSampleBE = audioChunk.readInt16BE(0);
            console.log(`[FishAudioTTS] ğŸ“Š First sample (Little Endian): ${firstSampleLE}`);
            console.log(`[FishAudioTTS] ğŸ“Š First sample (Big Endian): ${firstSampleBE}`);
            
            // ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’ç¢ºèªï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã®å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
            const allSamples = new Int16Array(
              audioChunk.buffer,
              audioChunk.byteOffset,
              audioChunk.length / 2,
            );
            if (allSamples.length > 0) {
              const samplesArray = Array.from(allSamples);
              const minSample = Math.min(...samplesArray);
              const maxSample = Math.max(...samplesArray);
              console.log(`[FishAudioTTS] ğŸ“Š Sample range: [${minSample}, ${maxSample}] (Int16 range: [-32768, 32767])`);
              
              // ã‚¼ãƒ­ã‚¯ãƒ­ãƒƒã‚·ãƒ³ã‚°ã®é »åº¦ã‚’ç¢ºèªï¼ˆæ­£å¸¸ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ãªã‚‰é©åº¦ãªã‚¼ãƒ­ã‚¯ãƒ­ãƒƒã‚·ãƒ³ã‚°ãŒã‚ã‚‹ï¼‰
              let zeroCrossings = 0;
              for (let i = 1; i < allSamples.length; i++) {
                const prevSample = allSamples[i - 1]!;
                const currSample = allSamples[i]!;
                if ((prevSample >= 0 && currSample < 0) || (prevSample < 0 && currSample >= 0)) {
                  zeroCrossings++;
                }
              }
              console.log(`[FishAudioTTS] ğŸ“Š Zero crossings: ${zeroCrossings} (${((zeroCrossings / allSamples.length) * 100).toFixed(2)}%)`);
              
              // ç•°å¸¸ãªãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
              if (Math.abs(minSample) > 32767 || Math.abs(maxSample) > 32767) {
                console.log(`[FishAudioTTS] âš ï¸ WARNING: Sample values exceed Int16 range!`);
              }
              if (zeroCrossings === 0) {
                console.log(`[FishAudioTTS] âš ï¸ WARNING: No zero crossings detected - data may be corrupted or DC offset`);
              }
            }
          }
          
          firstChunkReceived = true;
        }
        
        // Buffer ã‚’ Int16Array (PCM) ã«å¤‰æ›
        const allSamples = new Int16Array(
          audioChunk.buffer,
          audioChunk.byteOffset,
          audioChunk.length / 2,
        );
        
        // ãƒãƒ£ãƒ³ã‚¯ã®æŒ¯å¹…ã‚’è¨ˆç®—
        let chunkAbsMax = 0;
        let minSample = 0;
        let maxSample = 0;
        if (allSamples.length > 0) {
          const samplesArray = Array.from(allSamples);
          minSample = Math.min(...samplesArray);
          maxSample = Math.max(...samplesArray);
          chunkAbsMax = Math.max(Math.abs(minSample), Math.abs(maxSample));
        }
        
        // æ­£å¸¸ãªæŒ¯å¹…ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç‰¹å®šã—ã¦ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if (chunkAbsMax > 1000 && totalChunks > 15 && totalChunks <= 30) {
          // Chunk 15-30ã§æ­£å¸¸ãªæŒ¯å¹…ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
          const debugDir = path.join(process.cwd(), 'debug-audio');
          if (!fs.existsSync(debugDir)) {
            fs.mkdirSync(debugDir, { recursive: true });
          }
          const debugFile = path.join(debugDir, `chunk-${totalChunks}-normal-amplitude.bin`);
          fs.writeFileSync(debugFile, Buffer.from(audioChunk));
          console.log(`[FishAudioTTS] ğŸ’¾ Saved normal amplitude chunk ${totalChunks} (absMax=${chunkAbsMax}, range=[${minSample}, ${maxSample}]) to: ${debugFile}`);
          
          // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è©³ç´°ã«åˆ†æ
          const detectedFormat = detectAudioFormat(audioChunk);
          console.log(`[FishAudioTTS] ğŸ” Normal chunk ${totalChunks} format: ${detectedFormat}`);
          console.log(`[FishAudioTTS] ğŸ” Normal chunk ${totalChunks} hex preview: ${audioChunk.slice(0, Math.min(32, audioChunk.length)).toString('hex')}`);
        }
        
        // ç•°å¸¸ãªæŒ¯å¹…ã®ãƒãƒ£ãƒ³ã‚¯ã‚‚è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if (chunkAbsMax > 0 && chunkAbsMax < 100 && totalChunks <= 20) {
          console.log(`[FishAudioTTS] âš ï¸ Low amplitude chunk ${totalChunks}: absMax=${chunkAbsMax}, range=[${minSample}, ${maxSample}]`);
          // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è©³ç´°ã«åˆ†æ
          const detectedFormat = detectAudioFormat(audioChunk);
          console.log(`[FishAudioTTS] ğŸ” Low amplitude chunk ${totalChunks} format: ${detectedFormat}`);
          console.log(`[FishAudioTTS] ğŸ” Low amplitude chunk ${totalChunks} hex preview: ${audioChunk.slice(0, Math.min(32, audioChunk.length)).toString('hex')}`);
        }
        
        // éŸ³å£°é–‹å§‹ã®æ¤œå‡ºï¼ˆæŒ¯å¹…ãŒé–¾å€¤ä»¥ä¸Šã®å ´åˆã€éŸ³å£°ãŒé–‹å§‹ã•ã‚ŒãŸã¨ã¿ãªã™ï¼‰
        if (!audioStarted && chunkAbsMax >= SILENCE_THRESHOLD) {
          audioStarted = true;
          console.log(`[FishAudioTTS] ğŸ”Š Audio started at chunk ${totalChunks} (absMax=${chunkAbsMax})`);
        }
        
        // ç„¡éŸ³ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚­ãƒƒãƒ—ï¼ˆéŸ³å£°é–‹å§‹å‰ã®ã¿ï¼‰
        // éŸ³å£°é–‹å§‹å¾Œã¯ç„¡éŸ³ãƒãƒ£ãƒ³ã‚¯ã‚‚é€ä¿¡ã™ã‚‹ï¼ˆéŸ³å£°ã®é€”ä¸­ã§ç„¡éŸ³ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
        if (!audioStarted && chunkAbsMax < SILENCE_THRESHOLD) {
          // éŸ³å£°é–‹å§‹å‰ã«ç„¡éŸ³ãŒç¶šãå ´åˆã®ã¿ã‚¹ã‚­ãƒƒãƒ—
          if (totalChunks <= MAX_SILENT_CHUNKS_BEFORE_START) {
            console.log(`[FishAudioTTS] â­ï¸ Skipping silent chunk ${totalChunks} before audio start (absMax=${chunkAbsMax})`);
            continue; // ã“ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã¸
          } else {
            // æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—æ•°ã‚’è¶…ãˆãŸå ´åˆã¯ã€ç„¡éŸ³ã§ã‚‚é€ä¿¡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
            console.log(`[FishAudioTTS] âš ï¸ Max silent chunks reached, sending chunk ${totalChunks} even though silent (absMax=${chunkAbsMax})`);
            audioStarted = true; // å¼·åˆ¶çš„ã«éŸ³å£°é–‹å§‹ã¨ã¿ãªã™
          }
        }
        
        // ã‚²ã‚¤ãƒ³èª¿æ•´ã®ãŸã‚ã®æœ€å¤§æŒ¯å¹…ã‚’è¿½è·¡ï¼ˆæœ€åˆã®æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if (allSamples.length > 0 && totalChunks > 5 && totalChunks <= GAIN_CALIBRATION_CHUNKS) {
          const samplesArray = Array.from(allSamples);
          const minSample = Math.min(...samplesArray);
          const maxSample = Math.max(...samplesArray);
          const absMax = Math.max(Math.abs(minSample), Math.abs(maxSample));
          if (absMax > globalMaxAmplitude) {
            globalMaxAmplitude = absMax;
            console.log(`[FishAudioTTS] ğŸ“Š Calibration chunk ${totalChunks}: range=[${minSample}, ${maxSample}], absMax=${absMax}, globalMax=${globalMaxAmplitude}`);
          }
        }
        
        // ã‚²ã‚¤ãƒ³ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã‚’æ±ºå®šï¼ˆæœ€åˆã®æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—å¾Œï¼‰
        if (totalChunks === GAIN_CALIBRATION_CHUNKS && gainFactor === null) {
          console.log(`[FishAudioTTS] ğŸ” Calibration complete: globalMaxAmplitude=${globalMaxAmplitude}, MIN_AMPLITUDE_THRESHOLD=${MIN_AMPLITUDE_THRESHOLD}`);
          if (globalMaxAmplitude > 0 && globalMaxAmplitude < MIN_AMPLITUDE_THRESHOLD) {
            // ä½æŒ¯å¹…ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€çµ±ä¸€çš„ãªã‚²ã‚¤ãƒ³ã‚’è¨ˆç®—
            gainFactor = Math.min(
              MAX_GAIN_FACTOR,
              Math.floor((MIN_AMPLITUDE_THRESHOLD * 10) / globalMaxAmplitude)
            );
            console.log(`[FishAudioTTS] ğŸ”Š Global max amplitude: ${globalMaxAmplitude}, applying unified gain: ${gainFactor}x`);
          } else {
            // æ­£å¸¸ãªæŒ¯å¹…ç¯„å›²ã®å ´åˆã€ã‚²ã‚¤ãƒ³ã¯ä¸è¦
            gainFactor = 1;
            console.log(`[FishAudioTTS] âœ“ Normal amplitude detected (max: ${globalMaxAmplitude}), no gain needed`);
          }
        }
        
        // ã‚²ã‚¤ãƒ³ã‚’é©ç”¨ï¼ˆã‚²ã‚¤ãƒ³ãŒæ±ºå®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
        let pcmData: Int16Array;
        if (gainFactor !== null && gainFactor > 1) {
          const scaledSamples = new Int16Array(allSamples.length);
          for (let i = 0; i < allSamples.length; i++) {
            const scaled = allSamples[i]! * gainFactor;
            // ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚’é˜²æ­¢
            scaledSamples[i] = Math.max(-32767, Math.min(32767, scaled));
          }
          pcmData = scaledSamples;
        } else {
          // ã‚²ã‚¤ãƒ³ãŒã¾ã æ±ºå®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ã¾ãŸã¯ä¸è¦ãªå ´åˆ
          pcmData = allSamples;
        }
        
        // LiveKit AudioFrame ã«å¤‰æ›
        const samplesPerChannel = pcmData.length / this.ttsInstance.numChannels;
        const audioFrame = new AudioFrame(
          pcmData,
          this.ttsInstance.sampleRate,
          this.ttsInstance.numChannels,
          samplesPerChannel,
        );
        const audio = {
          requestId: '',
          segmentId: `segment-${segmentId++}`,
          frame: audioFrame,
          final: false, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã¯ false
        };
        this.queue.put(audio);
      }
      
      const totalTime = Date.now() - sessionStartTime;
      console.log(
        `[FishAudioTTS] â±ï¸ Total audio generation: ${totalTime}ms (${totalChunks} chunks)`,
      );
      
      // ä¿å­˜ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã—ã¦è©³ç´°åˆ†æ
      if (allChunksForAnalysis.length > 0) {
        const combinedData = Buffer.concat(allChunksForAnalysis);
        console.log(`[FishAudioTTS] ğŸ” Analyzing ${allChunksForAnalysis.length} chunks (${combinedData.length} bytes total)`);
        
        // çµåˆã—ãŸãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’åˆ¤å®š
        const combinedFormat = detectAudioFormat(combinedData);
        console.log(`[FishAudioTTS] ğŸ” Combined data format: ${combinedFormat}`);
        
        // ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const debugDir = path.join(process.cwd(), 'debug-audio');
        if (!fs.existsSync(debugDir)) {
          fs.mkdirSync(debugDir, { recursive: true });
        }
        const debugFile = path.join(debugDir, `fish-audio-${timestamp}-${totalChunks}chunks.bin`);
        fs.writeFileSync(debugFile, combinedData);
        console.log(`[FishAudioTTS] ğŸ’¾ Saved first ${allChunksForAnalysis.length} chunks to: ${debugFile}`);
        console.log(`[FishAudioTTS] ğŸ’¾ File size: ${combinedData.length} bytes`);
        console.log(`[FishAudioTTS] ğŸ’¾ To analyze: file ${debugFile} | xxd | head -20`);
        
        // ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›
        const byteCounts = new Array(256).fill(0);
        const sampleSize = Math.min(1000, combinedData.length);
        for (let i = 0; i < sampleSize; i++) {
          byteCounts[combinedData[i]!]++;
        }
        const mostCommonBytes = byteCounts
          .map((count, byte) => ({ byte, count }))
          .sort((a, b) => b.count - a.count)
          .slice(0, 5);
        console.log(`[FishAudioTTS] ğŸ“Š Most common bytes in first ${sampleSize} bytes:`, 
          mostCommonBytes.map(({ byte, count }) => `0x${byte.toString(16).padStart(2, '0').toUpperCase()}:${count}`).join(', '));
      }
      
      console.log('[FishAudioTTS] HTTP API streaming synthesis session completed');
    } catch (error) {
      console.error('[FishAudioTTS] HTTP API streaming error:', error);
      // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
      if (error instanceof Error) {
        console.error('[FishAudioTTS] Error name:', error.name);
        console.error('[FishAudioTTS] Error message:', error.message);
        console.error('[FishAudioTTS] Error stack:', error.stack);
        if ('code' in error) {
          console.error('[FishAudioTTS] Error code:', (error as any).code);
        }
        if ('details' in error) {
          console.error('[FishAudioTTS] Error details:', (error as any).details);
        }
      }
      console.error('[FishAudioTTS] Backend used:', this.ttsInstance.backend);
      console.error('[FishAudioTTS] Voice ID:', this.ttsInstance.voiceId);
      throw error;
    }
  }

}

