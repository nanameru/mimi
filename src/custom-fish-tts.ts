import { tts } from '@livekit/agents';
import { AudioFrame } from '@livekit/rtc-node';
import { Session, TTSRequest, type Backends } from 'fish-audio-sdk';
import * as fs from 'fs';
import * as path from 'path';

/**
 * Fish Audio TTS è¨­å®š
 * å…¬å¼ fish-audio-sdk ã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°åˆæˆ
 * HTTP APIã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
 * æ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã®æœ€é©åŒ–ã‚’å®Ÿè£…
 * ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: https://docs.fish.audio/api-reference/introduction
 * npm: https://www.npmjs.com/package/fish-audio-sdk
 */
export interface FishAudioTTSOptions {
  apiKey?: string;
  voiceId?: string;
  sampleRate?: number;
  numChannels?: number;
  backend?: Backends;
  chunkLength?: number;
  latency?: 'normal' | 'balanced';
}


/**
 * Fish Audio TTS å®Ÿè£…
 * HTTP APIã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
 * æ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã¨HTTP/2ã®æœ€é©åŒ–ã‚’å®Ÿè£…
 */
export class FishAudioTTS extends tts.TTS {
  label = 'fish-audio-tts';
  public apiKey: string;
  public voiceId: string;
  public backend: Backends;
  public chunkLength: number;
  public latency: 'normal' | 'balanced';
  public httpSession: Session;

  constructor(options: FishAudioTTSOptions = {}) {
    const sampleRate = options.sampleRate || 44100;
    const numChannels = options.numChannels || 1;
    // TTS capabilities ã‚’è¨­å®šï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
    super(sampleRate, numChannels, {
      streaming: true,
    });
    this.apiKey = options.apiKey || process.env.FISH_AUDIO_API_KEY || '';
    this.voiceId = options.voiceId || process.env.FISH_AUDIO_VOICE_ID || '';
    this.backend = options.backend || 'speech-1.5';
    this.chunkLength = options.chunkLength || 100;
    this.latency = options.latency || 'balanced';
    if (!this.apiKey) {
      throw new Error('FISH_AUDIO_API_KEY is required');
    }
    // HTTP Session ã‚’åˆæœŸåŒ–ï¼ˆæ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–ï¼‰
    // fish-audio-sdkã®Sessionã‚¯ãƒ©ã‚¹ã¯æ—¢ã«keepAliveã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€
    // åŸºæœ¬çš„ãªæ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã™
    // ã‚ˆã‚Šè©³ç´°ãªæœ€é©åŒ–ï¼ˆmaxSockets, maxFreeSocketsãªã©ï¼‰ãŒå¿…è¦ãªå ´åˆã¯ã€
    // fish-audio-sdkã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
    // HTTP/2ã®ã‚µãƒãƒ¼ãƒˆã«ã¤ã„ã¦ã¯ã€Fish Audio APIãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‹ç¢ºèªãŒå¿…è¦ã§ã™
    this.httpSession = new Session(this.apiKey);
    console.log(
      `[FishAudioTTS] Initialized with HTTP API: backend=${this.backend}, voiceId=${this.voiceId ? 'set' : 'not set'}, sampleRate=${sampleRate}Hz, channels=${numChannels}`,
    );
    console.log('[FishAudioTTS] Connection pooling: keepAlive=true (fish-audio-sdk default)');
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’åˆæˆï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
   */
  synthesize(text: string): tts.ChunkedStream {
    console.log(`[FishAudioTTS] Synthesizing text (length=${text.length})`);
    return new FishAudioChunkedStream(text, this);
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° TTS
   */
  stream(): tts.SynthesizeStream {
    console.log('[FishAudioTTS] Creating streaming session');
    return new FishAudioSynthesizeStream(this);
  }

  /**
   * ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
   */
  async close(): Promise<void> {
    this.httpSession.close();
    console.log('[FishAudioTTS] HTTP session closed');
  }
}

/**
 * Fish Audio ãƒãƒ£ãƒ³ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆæˆç”¨ï¼‰
 */
class FishAudioChunkedStream extends tts.ChunkedStream {
  label = 'fish-audio-chunked-stream';
  private text: string;
  private ttsInstance: FishAudioTTS;

  constructor(text: string, ttsInstance: FishAudioTTS) {
    super(text, ttsInstance);
    this.text = text;
    this.ttsInstance = ttsInstance;
  }

  async run() {
    try {
      console.log('[FishAudioTTS] Starting non-streaming synthesis');
      // TTSRequest ã‚’ä½œæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã‚‹ï¼‰
      const request = new TTSRequest(this.text, {
        referenceId: this.ttsInstance.voiceId,
        format: 'pcm',
        sampleRate: this.ttsInstance.sampleRate,
        chunkLength: this.ttsInstance.chunkLength,
        latency: this.ttsInstance.latency,
        normalize: true,
      });
      
      // curlã‚³ãƒãƒ³ãƒ‰ã®å½¢å¼ã«åˆã‚ã›ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’æ‹¡å¼µ
      const requestPayload = request.toJSON() as any;
      // temperatureã¨top_pã‚’è¿½åŠ ï¼ˆcurlã‚³ãƒãƒ³ãƒ‰ã¨åŒã˜å€¤ï¼‰
      requestPayload.temperature = 0.9;
      requestPayload.top_p = 0.9;
      // reference_idãŒç©ºæ–‡å­—åˆ—ã®å ´åˆã¯undefinedã«è¨­å®š
      if (!requestPayload.reference_id || (typeof requestPayload.reference_id === 'string' && requestPayload.reference_id.trim() === '')) {
        requestPayload.reference_id = undefined;
      }
      
      // HTTP APIã§éŸ³å£°ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰
      // curlã‚³ãƒãƒ³ãƒ‰ã®å½¢å¼ã«åˆã‚ã›ã¦ç›´æ¥HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆtemperatureã¨top_pã‚’å«ã‚ã‚‹ï¼‰
      // Sessionã‚¯ãƒ©ã‚¹ã®clientã‚’ä½¿ç”¨ã—ã¦HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
      const response = await (this.ttsInstance.httpSession as any).client.post('/v1/tts', requestPayload, {
        responseType: 'stream',
        headers: {
          'Content-Type': 'application/json',
          model: this.ttsInstance.backend,
        },
      });
      
      // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
      console.log('TTS Response Content-Type:', response.headers['content-type']);
      console.log('TTS Response headers:', JSON.stringify(response.headers, null, 2));
      
      const audioChunks: Buffer[] = [];
      let firstChunkForSynthesize = true;
      for await (const chunk of response.data) {
        const audioChunk = Buffer.from(chunk);
        // æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®å…ˆé ­ãƒã‚¤ãƒˆã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šç”¨ï¼‰
        if (firstChunkForSynthesize) {
          const firstChunkPreview = chunk.slice(0, Math.min(32, chunk.length));
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (hex): ${firstChunkPreview.toString('hex')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk length: ${chunk.length} bytes`);
          
          // MP3ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ç¢ºèª
          const firstBytes = chunk.slice(0, 4);
          const hexString = firstBytes.toString('hex').toUpperCase();
          if (hexString.startsWith('FF')) {
            console.log(`[FishAudioTTS] âš ï¸ WARNING: First bytes suggest MP3 format (${hexString}), but PCM format was requested!`);
            console.log(`[FishAudioTTS] âš ï¸ This may cause audio quality issues. MP3 decoding may be required.`);
          } else {
            console.log(`[FishAudioTTS] âœ“ First bytes suggest PCM format (${hexString})`);
            
            // PCMãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç¢ºèª
            if (chunk.length >= 2) {
              const firstSampleLE = chunk.readInt16LE(0);
              const firstSampleBE = chunk.readInt16BE(0);
              console.log(`[FishAudioTTS] ğŸ“Š First sample (Little Endian): ${firstSampleLE}`);
              console.log(`[FishAudioTTS] ğŸ“Š First sample (Big Endian): ${firstSampleBE}`);
            }
          }
          firstChunkForSynthesize = false;
        }
        audioChunks.push(chunk);
      }
      // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
      const audioBuffer = Buffer.concat(audioChunks);
      console.log(`[FishAudioTTS] Received ${audioBuffer.length} bytes of audio`);
      // LiveKit AudioFrame ã«å¤‰æ›
      const pcmData = new Int16Array(
        audioBuffer.buffer,
        audioBuffer.byteOffset,
        audioBuffer.length / 2,
      );
      const samplesPerChannel = pcmData.length / this.ttsInstance.numChannels;
      const audioFrame = new AudioFrame(
        pcmData,
        this.ttsInstance.sampleRate,
        this.ttsInstance.numChannels,
        samplesPerChannel,
      );
      const audio = {
        requestId: '',
        segmentId: 'segment-0',
        frame: audioFrame,
        final: true,
      };
      this.queue.put(audio);
      console.log('[FishAudioTTS] Synthesis completed');
    } catch (error) {
      console.error('[FishAudioTTS] Error:', error);
      throw error;
    }
  }
}

/**
 * Fish Audio ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…
 * LLM ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŸ³å£°ã«å¤‰æ›
 */
class FishAudioSynthesizeStream extends tts.SynthesizeStream {
  label = 'fish-audio-synthesize-stream';
  private ttsInstance: FishAudioTTS;

  constructor(ttsInstance: FishAudioTTS) {
    super(ttsInstance);
    this.ttsInstance = ttsInstance;
  }

  async run() {
    try {
      const sessionStartTime = Date.now();
      console.log(
        `[FishAudioTTS] [${new Date().toLocaleTimeString()}] Starting HTTP API streaming synthesis session`,
      );
      
      // LLMã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å®Œå…¨ã«å—ä¿¡
      const textReceiveStartTime = Date.now();
      const textBuffer: string[] = [];
      for await (const text of this.input) {
        if (text === FishAudioSynthesizeStream.FLUSH_SENTINEL) {
          // FLUSH_SENTINELãŒæ¥ãŸã‚‰ã€ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
          if (textBuffer.length > 0) {
            break; // ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦HTTP APIã«é€ä¿¡
          }
          continue;
        }
        textBuffer.push(text);
      }
      
      // ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
      let fullText = textBuffer.join('');
      const textReceiveEndTime = Date.now();
      const textReceiveDuration = textReceiveEndTime - textReceiveStartTime;
      
      console.log(`[FishAudioTTS] â±ï¸ Text receive duration: ${textReceiveDuration}ms (${fullText.length} chars)`);
      
      // ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’æ¤œå‡ºã—ã¦ãƒ­ã‚°ã«è¨˜éŒ²
      const emotionTags = fullText.match(/\([^)]+\)/g) || [];
      if (emotionTags.length > 0) {
        console.log(
          `[FishAudioTTS] ğŸ·ï¸ Detected ${emotionTags.length} emotion tag(s): ${emotionTags.join(', ')}`,
        );
        console.log(
          `[FishAudioTTS] ğŸ“ Original text: "${fullText.substring(0, 100)}${fullText.length > 100 ? '...' : ''}"`,
        );
      }
      
      // ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã®å‰å‡¦ç†: æ–‡ã®æœ€åˆã®ã‚¿ã‚°ã®ã¿ã‚’ä¿æŒï¼ˆFish Audioã¯æœ€åˆã®ã‚¿ã‚°ã®ã¿ã‚’èªè­˜ã™ã‚‹å¯èƒ½æ€§ï¼‰
      // 1. å…¨ã¦ã®ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’æŠ½å‡º
      const allEmotionTags = fullText.match(/\([^)]+\)/g) || [];
      if (allEmotionTags.length > 0) {
        // 2. ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰å…¨ã¦ã®ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’ä¸€æ™‚çš„ã«å‰Šé™¤
        let cleanedText = fullText.replace(/\([^)]+\)/g, '').trim();
        
        // 3. æ–‡ã®æœ€åˆã®ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã®ã¿ã‚’å…ˆé ­ã«é…ç½®
        // è¤‡æ•°ã®ã‚¿ã‚°ãŒã‚ã‚‹å ´åˆã€æœ€åˆã®ã‚¿ã‚°ã‚’å„ªå…ˆï¼ˆã‚ˆã‚Šå¼·ã„æ„Ÿæƒ…è¡¨ç¾ã¨ã—ã¦èªè­˜ã•ã‚Œã‚‹å¯èƒ½æ€§ï¼‰
        const firstEmotionTag = allEmotionTags[0]!;
        
        // 4. æœ€åˆã®ã‚¿ã‚°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã®å…ˆé ­ã«é…ç½®
        fullText = `${firstEmotionTag} ${cleanedText}`;
        
        console.log(
          `[FishAudioTTS] ğŸ”§ Preprocessed text: "${fullText.substring(0, 100)}${fullText.length > 100 ? '...' : ''}"`,
        );
        console.log(
          `[FishAudioTTS] ğŸ“Œ Using first emotion tag only: ${firstEmotionTag} (${allEmotionTags.length - 1} tag(s) removed)`,
        );
      }
      
      console.log(
        `[FishAudioTTS] ğŸ“¤ [${new Date().toLocaleTimeString()}] Sending text to HTTP API (${fullText.length} chars): "${fullText.substring(0, 50)}..."`,
      );
      
      // HTTP APIã§éŸ³å£°ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰
      // curlã‚³ãƒãƒ³ãƒ‰ã®å½¢å¼ã«åˆã‚ã›ã¦temperatureã¨top_pã‚’è¿½åŠ 
      // ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‚’ãã®ã¾ã¾é€ä¿¡ï¼ˆFish Audio APIãŒå‡¦ç†ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
      const request = new TTSRequest(fullText, {
        referenceId: this.ttsInstance.voiceId,
        format: 'pcm',
        sampleRate: this.ttsInstance.sampleRate,
        chunkLength: this.ttsInstance.chunkLength,
        latency: this.ttsInstance.latency,
        normalize: true,
      });
      
      // curlã‚³ãƒãƒ³ãƒ‰ã®å½¢å¼ã«åˆã‚ã›ã¦ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒœãƒ‡ã‚£ã‚’æ‹¡å¼µ
      const requestPayload = request.toJSON() as any;
      // temperatureã¨top_pã‚’è¿½åŠ ï¼ˆcurlã‚³ãƒãƒ³ãƒ‰ã¨åŒã˜å€¤ï¼‰
      requestPayload.temperature = 0.9;
      requestPayload.top_p = 0.9;
      // reference_idãŒç©ºæ–‡å­—åˆ—ã®å ´åˆã¯undefinedã«è¨­å®š
      if (!requestPayload.reference_id || (typeof requestPayload.reference_id === 'string' && requestPayload.reference_id.trim() === '')) {
        requestPayload.reference_id = undefined;
      }
      
      let segmentId = 0;
      let firstChunkReceived = false;
      let firstChunkTimeFromHttpRequest = 0;
      let totalChunks = 0;
      let globalMaxAmplitude = 0;
      let gainFactor: number | null = null;
      const GAIN_CALIBRATION_CHUNKS = 20; // æœ€åˆã®20ãƒãƒ£ãƒ³ã‚¯ã§ã‚²ã‚¤ãƒ³ã‚’æ±ºå®š
      const MAX_GAIN_FACTOR = 100; // æœ€å¤§ã‚²ã‚¤ãƒ³å€ç‡ï¼ˆæ¥µç«¯ãªå¢—å¹…ã‚’é˜²ãï¼‰
      const MIN_AMPLITUDE_THRESHOLD = 100; // ã“ã®å€¤æœªæº€ã®å ´åˆã€å¢—å¹…ãŒå¿…è¦
      
      // ç„¡éŸ³ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚­ãƒƒãƒ—ç”¨å¤‰æ•°
      let audioStarted = false; // éŸ³å£°ãŒé–‹å§‹ã•ã‚ŒãŸã‹ã©ã†ã‹
      const SILENCE_THRESHOLD = 100; // ã“ã®å€¤æœªæº€ã¯ç„¡éŸ³ã¨ã¿ãªã™
      const MAX_SILENT_CHUNKS_BEFORE_START = 50; // éŸ³å£°é–‹å§‹å‰ã«ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹æœ€å¤§ãƒãƒ£ãƒ³ã‚¯æ•°
      
      // ãƒ•ãƒ¬ãƒ¼ãƒ ã‚µã‚¤ã‚ºã®æ­£è¦åŒ–ï¼ˆå¯å¤‰é•·ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸€å®šã‚µã‚¤ã‚ºã®ãƒ•ãƒ¬ãƒ¼ãƒ ã«å†åˆ†å‰²ï¼‰
      // 44100Hz * 0.015625ç§’ = 689.0625ã‚µãƒ³ãƒ—ãƒ« â†’ 689ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæœ€ã‚‚ä¸€èˆ¬çš„ãªã‚µã‚¤ã‚ºï¼‰
      const TARGET_SAMPLES_PER_FRAME = 689; // 15.62ms @ 44100Hz
      const TARGET_FRAME_SIZE = TARGET_SAMPLES_PER_FRAME * 2; // 2 bytes per sample (Int16)
      let pcmBuffer = Buffer.alloc(0); // å—ä¿¡ã—ãŸPCMãƒ‡ãƒ¼ã‚¿ã‚’è“„ç©ã™ã‚‹ãƒãƒƒãƒ•ã‚¡
      let framesSent = 0; // LiveKitã«é€ä¿¡ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°
      let framesSkipped = 0; // ã‚¹ã‚­ãƒƒãƒ—ã—ãŸãƒ•ãƒ¬ãƒ¼ãƒ æ•°ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
      const MAX_SILENT_FRAMES_AFTER_START = 20; // éŸ³å£°é–‹å§‹å¾Œã®ä½æŒ¯å¹…ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹æœ€å¤§æ•°
      
      // ãƒ‡ãƒ¼ã‚¿å½¢å¼åˆ¤å®šç”¨ã®å¤‰æ•°
      let allChunksForAnalysis: Buffer[] = [];
      const MAX_CHUNKS_FOR_ANALYSIS = 50; // æœ€åˆã®50ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ã—ã¦åˆ†æï¼ˆæ­£å¸¸ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰
      
      // å…¨ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
      const allChunksForLogging: Buffer[] = [];
      
      // ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®šï¼ˆæ—¥ä»˜ã¨æ™‚é–“ã”ã¨ã«åˆ†å‰²ï¼‰
      const now = new Date();
      const dateStr = now.toISOString().split('T')[0]!; // YYYY-MM-DDå½¢å¼
      const timeStr = now.toTimeString().split(' ')[0]!.replace(/:/g, '-').substring(0, 5); // HH-MMå½¢å¼ï¼ˆç§’ã¯é™¤å¤–ï¼‰
      const debugBaseDir = path.join(process.cwd(), 'debug-audio');
      const debugDateDir = path.join(debugBaseDir, dateStr, timeStr);
      if (!fs.existsSync(debugDateDir)) {
        fs.mkdirSync(debugDateDir, { recursive: true });
      }
      
      console.log(`[FishAudioTTS] Starting HTTP API TTS with backend: ${this.ttsInstance.backend}, voiceId: ${this.ttsInstance.voiceId || 'not set'}`);
      console.log(`[FishAudioTTS] ğŸ“‹ Request payload: ${JSON.stringify(requestPayload, null, 2)}`);
      
      // HTTP APIãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡é–‹å§‹
      const httpRequestStartTime = Date.now();
      
      // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’åˆ¤å®šã™ã‚‹é–¢æ•°
      const detectAudioFormat = (data: Buffer): string => {
        if (data.length < 4) return 'UNKNOWN';
        
        const firstBytes = data.slice(0, 4);
        const hexString = firstBytes.toString('hex').toUpperCase();
        
        // MP3å½¢å¼ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        // MP3: FF FB, FF F3, FF F2, FF FA, FF E3, FF E2, FF E1, FF E0
        if (hexString.startsWith('FF')) {
          const secondByte = firstBytes[1];
          if (secondByte === 0xFB || secondByte === 0xF3 || secondByte === 0xF2 || secondByte === 0xFA ||
              secondByte === 0xE3 || secondByte === 0xE2 || secondByte === 0xE1 || secondByte === 0xE0) {
            return 'MP3';
          }
        }
        
        // WAVå½¢å¼ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        // WAV: 52 49 46 46 (RIFF) ã¾ãŸã¯ 52 49 46 46 (RIFF) + 57 41 56 45 (WAVE)
        if (data.length >= 12) {
          const riffHeader = data.slice(0, 4).toString('ascii');
          if (riffHeader === 'RIFF') {
            const waveHeader = data.slice(8, 12).toString('ascii');
            if (waveHeader === 'WAVE') {
              return 'WAV';
            }
          }
        }
        
        // Opuså½¢å¼ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯
        // Opus: OggS (4F 67 67 53)
        if (data.length >= 4) {
          const oggHeader = data.slice(0, 4).toString('ascii');
          if (oggHeader === 'OggS') {
            return 'OPUS';
          }
        }
        
        // PCMå½¢å¼ã®åˆ¤å®šï¼ˆãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆçš„ç‰¹æ€§ã‹ã‚‰ï¼‰
        // PCMãƒ‡ãƒ¼ã‚¿ã¯é€šå¸¸ã€ãƒ©ãƒ³ãƒ€ãƒ ãªãƒã‚¤ãƒˆåˆ†å¸ƒã‚’æŒã¤
        // ã—ã‹ã—ã€æœ€åˆã®æ•°ãƒã‚¤ãƒˆãŒå…¨ã¦0xFFã‚„0x00ã®å ´åˆã¯ã€ä»–ã®å½¢å¼ã®å¯èƒ½æ€§ãŒã‚ã‚‹
        const first16Bytes = data.slice(0, Math.min(16, data.length));
        const uniqueBytes = new Set(Array.from(first16Bytes)).size;
        
        // å…¨ã¦åŒã˜ãƒã‚¤ãƒˆå€¤ï¼ˆ0xFFã‚„0x00ãªã©ï¼‰ã®å ´åˆã¯ã€PCMã§ã¯ãªã„å¯èƒ½æ€§ãŒé«˜ã„
        if (uniqueBytes === 1) {
          return 'SUSPICIOUS (all same bytes)';
        }
        
        // ãƒã‚¤ãƒˆã®åˆ†å¸ƒã‚’ç¢ºèªï¼ˆã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã®ç°¡å˜ãªãƒã‚§ãƒƒã‚¯ï¼‰
        const byteCounts = new Array(256).fill(0);
        const sampleSize = Math.min(256, data.length);
        for (let i = 0; i < sampleSize; i++) {
          byteCounts[data[i]!]++;
        }
        
        // ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒä½ã„å ´åˆï¼ˆç‰¹å®šã®ãƒã‚¤ãƒˆå€¤ã«åã£ã¦ã„ã‚‹ï¼‰ã€åœ§ç¸®å½¢å¼ã®å¯èƒ½æ€§
        const entropy = byteCounts.reduce((sum, count) => {
          if (count === 0) return sum;
          const p = count / sampleSize;
          return sum - p * Math.log2(p);
        }, 0);
        
        // ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ãŒä½ã„å ´åˆï¼ˆ< 5.0ï¼‰ã€åœ§ç¸®å½¢å¼ã®å¯èƒ½æ€§
        if (entropy < 5.0 && entropy > 0) {
          return `SUSPICIOUS (low entropy: ${entropy.toFixed(2)})`;
        }
        
        // ãƒ‡ãƒ¼ã‚¿ãŒ2ãƒã‚¤ãƒˆã®å€æ•°ã§ã€16-bit PCMã¨ã—ã¦è§£é‡ˆå¯èƒ½ãªå ´åˆ
        if (data.length % 2 === 0) {
          // ã‚µãƒ³ãƒ—ãƒ«å€¤ã‚’ç¢ºèªã—ã¦ã€Int16ã®ç¯„å›²å†…ã‹ãƒã‚§ãƒƒã‚¯
          const samples = new Int16Array(data.buffer, data.byteOffset, Math.min(100, data.length / 2));
          const minSample = Math.min(...Array.from(samples));
          const maxSample = Math.max(...Array.from(samples));
          
          // Int16ã®ç¯„å›²å†…ã§ã‚ã‚Œã°ã€PCMã®å¯èƒ½æ€§ãŒé«˜ã„
          if (minSample >= -32768 && maxSample <= 32767) {
            return 'PCM (16-bit, Int16 range)';
          }
        }
        
        return 'UNKNOWN';
      };
      
      // curlã‚³ãƒãƒ³ãƒ‰ã®å½¢å¼ã«åˆã‚ã›ã¦ç›´æ¥HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ï¼ˆtemperatureã¨top_pã‚’å«ã‚ã‚‹ï¼‰
      // Sessionã‚¯ãƒ©ã‚¹ã®clientã‚’ä½¿ç”¨ã—ã¦HTTPãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡
      const response = await (this.ttsInstance.httpSession as any).client.post('/v1/tts', requestPayload, {
        responseType: 'stream',
        headers: {
          'Content-Type': 'application/json',
          model: this.ttsInstance.backend,
        },
      });
      
      // ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ãƒ­ã‚°ã«è¨˜éŒ²
      console.log('TTS Response Content-Type:', response.headers['content-type']);
      console.log('TTS Response headers:', JSON.stringify(response.headers, null, 2));
      
      for await (const chunk of response.data) {
        const audioChunk = Buffer.from(chunk);
        totalChunks++;
        
        // å…¨ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ï¼ˆãƒ­ã‚°ç”¨ï¼‰
        allChunksForLogging.push(Buffer.from(audioChunk));
        
        // æœ€åˆã®æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜ã—ã¦åˆ†æï¼ˆæ­£å¸¸ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€ï¼‰
        if (totalChunks <= MAX_CHUNKS_FOR_ANALYSIS) {
          allChunksForAnalysis.push(Buffer.from(audioChunk));
        }
        
        // æœ€åˆã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å—ä¿¡æ™‚ã®ãƒ­ã‚°
        if (!firstChunkReceived) {
          const firstChunkTime = Date.now() - sessionStartTime;
          firstChunkTimeFromHttpRequest = Date.now() - httpRequestStartTime;
          console.log(
            `[FishAudioTTS] â±ï¸ First audio chunk received after ${firstChunkTime}ms (from session start), ${firstChunkTimeFromHttpRequest}ms (from HTTP request)`,
          );
          // æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®å…ˆé ­ãƒã‚¤ãƒˆã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šç”¨ï¼‰
          const firstChunkPreview = audioChunk.slice(0, Math.min(32, audioChunk.length));
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (hex): ${firstChunkPreview.toString('hex')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (decimal): ${Array.from(firstChunkPreview).join(', ')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk length: ${audioChunk.length} bytes`);
          
          // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è©³ç´°ã«åˆ¤å®š
          const detectedFormat = detectAudioFormat(audioChunk);
          console.log(`[FishAudioTTS] ğŸ” Detected audio format: ${detectedFormat}`);
          
          // MP3ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ç¢ºèªï¼ˆFF FB, FF F3, FF F2, FF FAãªã©ï¼‰
          const firstBytes = audioChunk.slice(0, 4);
          const hexString = firstBytes.toString('hex').toUpperCase();
          if (hexString.startsWith('FF')) {
            console.log(`[FishAudioTTS] âš ï¸ WARNING: First bytes suggest MP3 format (${hexString}), but PCM format was requested!`);
            console.log(`[FishAudioTTS] âš ï¸ This may cause audio quality issues. MP3 decoding may be required.`);
          } else {
            console.log(`[FishAudioTTS] âœ“ First bytes suggest PCM format (${hexString})`);
          }
          
          // PCMãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’ç¢ºèª
          if (audioChunk.length >= 2) {
            const sampleCount = audioChunk.length / 2;
            console.log(`[FishAudioTTS] ğŸ“Š Estimated sample count: ${sampleCount} (assuming 16-bit PCM)`);
            console.log(`[FishAudioTTS] ğŸ“Š Estimated duration: ${(sampleCount / this.ttsInstance.sampleRate * 1000).toFixed(2)}ms`);
            
            // å®Ÿéš›ã®PCMãƒ‡ãƒ¼ã‚¿ã®å€¤ã‚’ç¢ºèªï¼ˆæœ€åˆã®10ã‚µãƒ³ãƒ—ãƒ«ï¼‰
            const pcmSamples = new Int16Array(
              audioChunk.buffer,
              audioChunk.byteOffset,
              Math.min(10, audioChunk.length / 2),
            );
            console.log(`[FishAudioTTS] ğŸ“Š First 10 PCM samples (Int16): [${Array.from(pcmSamples).join(', ')}]`);
            
            // ãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã¨ãƒ“ãƒƒã‚°ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã®ä¸¡æ–¹ã‚’ç¢ºèª
            const firstSampleLE = audioChunk.readInt16LE(0);
            const firstSampleBE = audioChunk.readInt16BE(0);
            console.log(`[FishAudioTTS] ğŸ“Š First sample (Little Endian): ${firstSampleLE}`);
            console.log(`[FishAudioTTS] ğŸ“Š First sample (Big Endian): ${firstSampleBE}`);
            
            // ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’ç¢ºèªï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã®å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
            const allSamples = new Int16Array(
              audioChunk.buffer,
              audioChunk.byteOffset,
              audioChunk.length / 2,
            );
            if (allSamples.length > 0) {
              const samplesArray = Array.from(allSamples);
              const minSample = Math.min(...samplesArray);
              const maxSample = Math.max(...samplesArray);
              console.log(`[FishAudioTTS] ğŸ“Š Sample range: [${minSample}, ${maxSample}] (Int16 range: [-32768, 32767])`);
              
              // ã‚¼ãƒ­ã‚¯ãƒ­ãƒƒã‚·ãƒ³ã‚°ã®é »åº¦ã‚’ç¢ºèªï¼ˆæ­£å¸¸ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ãªã‚‰é©åº¦ãªã‚¼ãƒ­ã‚¯ãƒ­ãƒƒã‚·ãƒ³ã‚°ãŒã‚ã‚‹ï¼‰
              let zeroCrossings = 0;
              for (let i = 1; i < allSamples.length; i++) {
                const prevSample = allSamples[i - 1]!;
                const currSample = allSamples[i]!;
                if ((prevSample >= 0 && currSample < 0) || (prevSample < 0 && currSample >= 0)) {
                  zeroCrossings++;
                }
              }
              console.log(`[FishAudioTTS] ğŸ“Š Zero crossings: ${zeroCrossings} (${((zeroCrossings / allSamples.length) * 100).toFixed(2)}%)`);
              
              // ç•°å¸¸ãªãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
              if (Math.abs(minSample) > 32767 || Math.abs(maxSample) > 32767) {
                console.log(`[FishAudioTTS] âš ï¸ WARNING: Sample values exceed Int16 range!`);
              }
              if (zeroCrossings === 0) {
                console.log(`[FishAudioTTS] âš ï¸ WARNING: No zero crossings detected - data may be corrupted or DC offset`);
              }
            }
          }
          
          firstChunkReceived = true;
        }
        
        // å—ä¿¡ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        pcmBuffer = Buffer.concat([pcmBuffer, audioChunk]);
        
        // ãƒãƒ£ãƒ³ã‚¯ã®æŒ¯å¹…ã‚’è¨ˆç®—ï¼ˆéŸ³å£°é–‹å§‹æ¤œå‡ºç”¨ï¼‰
        const chunkSamples = new Int16Array(
          audioChunk.buffer,
          audioChunk.byteOffset,
          audioChunk.length / 2,
        );
        
        let chunkAbsMax = 0;
        let minSample = 0;
        let maxSample = 0;
        if (chunkSamples.length > 0) {
          const samplesArray = Array.from(chunkSamples);
          minSample = Math.min(...samplesArray);
          maxSample = Math.max(...samplesArray);
          chunkAbsMax = Math.max(Math.abs(minSample), Math.abs(maxSample));
        }
        
        // æ­£å¸¸ãªæŒ¯å¹…ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ç‰¹å®šã—ã¦ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if (chunkAbsMax > 1000 && totalChunks > 15 && totalChunks <= 30) {
          // Chunk 15-30ã§æ­£å¸¸ãªæŒ¯å¹…ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ä¿å­˜
          const debugFile = path.join(debugDateDir, `chunk-${totalChunks}-normal-amplitude.bin`);
          fs.writeFileSync(debugFile, Buffer.from(audioChunk));
          console.log(`[FishAudioTTS] ğŸ’¾ Saved normal amplitude chunk ${totalChunks} (absMax=${chunkAbsMax}, range=[${minSample}, ${maxSample}]) to: ${debugFile}`);
          
          // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è©³ç´°ã«åˆ†æ
          const detectedFormat = detectAudioFormat(audioChunk);
          console.log(`[FishAudioTTS] ğŸ” Normal chunk ${totalChunks} format: ${detectedFormat}`);
          console.log(`[FishAudioTTS] ğŸ” Normal chunk ${totalChunks} hex preview: ${audioChunk.slice(0, Math.min(32, audioChunk.length)).toString('hex')}`);
        }
        
        // ç•°å¸¸ãªæŒ¯å¹…ã®ãƒãƒ£ãƒ³ã‚¯ã‚‚è¨˜éŒ²ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        if (chunkAbsMax > 0 && chunkAbsMax < 100 && totalChunks <= 20) {
          console.log(`[FishAudioTTS] âš ï¸ Low amplitude chunk ${totalChunks}: absMax=${chunkAbsMax}, range=[${minSample}, ${maxSample}]`);
          // ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’è©³ç´°ã«åˆ†æ
          const detectedFormat = detectAudioFormat(audioChunk);
          console.log(`[FishAudioTTS] ğŸ” Low amplitude chunk ${totalChunks} format: ${detectedFormat}`);
          console.log(`[FishAudioTTS] ğŸ” Low amplitude chunk ${totalChunks} hex preview: ${audioChunk.slice(0, Math.min(32, audioChunk.length)).toString('hex')}`);
        }
        
        // éŸ³å£°é–‹å§‹ã®æ¤œå‡ºï¼ˆæŒ¯å¹…ãŒé–¾å€¤ä»¥ä¸Šã®å ´åˆã€éŸ³å£°ãŒé–‹å§‹ã•ã‚ŒãŸã¨ã¿ãªã™ï¼‰
        if (!audioStarted && chunkAbsMax >= SILENCE_THRESHOLD) {
          audioStarted = true;
          console.log(`[FishAudioTTS] ğŸ”Š Audio started at chunk ${totalChunks} (absMax=${chunkAbsMax})`);
        }
        
        // ç„¡éŸ³ãƒãƒ£ãƒ³ã‚¯ã®ã‚¹ã‚­ãƒƒãƒ—ï¼ˆéŸ³å£°é–‹å§‹å‰ã®ã¿ï¼‰
        // éŸ³å£°é–‹å§‹å¾Œã¯ç„¡éŸ³ãƒãƒ£ãƒ³ã‚¯ã‚‚é€ä¿¡ã™ã‚‹ï¼ˆéŸ³å£°ã®é€”ä¸­ã§ç„¡éŸ³ã«ãªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
        if (!audioStarted && chunkAbsMax < SILENCE_THRESHOLD) {
          // éŸ³å£°é–‹å§‹å‰ã«ç„¡éŸ³ãŒç¶šãå ´åˆã®ã¿ã‚¹ã‚­ãƒƒãƒ—
          if (totalChunks <= MAX_SILENT_CHUNKS_BEFORE_START) {
            console.log(`[FishAudioTTS] â­ï¸ Skipping silent chunk ${totalChunks} before audio start (absMax=${chunkAbsMax})`);
            continue; // ã“ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¦æ¬¡ã®ãƒãƒ£ãƒ³ã‚¯ã¸
          } else {
            // æœ€å¤§ã‚¹ã‚­ãƒƒãƒ—æ•°ã‚’è¶…ãˆãŸå ´åˆã¯ã€ç„¡éŸ³ã§ã‚‚é€ä¿¡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒç ´æã—ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ï¼‰
            console.log(`[FishAudioTTS] âš ï¸ Max silent chunks reached, sending chunk ${totalChunks} even though silent (absMax=${chunkAbsMax})`);
            audioStarted = true; // å¼·åˆ¶çš„ã«éŸ³å£°é–‹å§‹ã¨ã¿ãªã™
          }
        }
        
        // ã‚²ã‚¤ãƒ³èª¿æ•´ã®ãŸã‚ã®æœ€å¤§æŒ¯å¹…ã‚’è¿½è·¡ï¼ˆæœ€åˆã®æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼‰
        if (chunkSamples.length > 0 && totalChunks > 5 && totalChunks <= GAIN_CALIBRATION_CHUNKS) {
          const samplesArray = Array.from(chunkSamples);
          const minSample = Math.min(...samplesArray);
          const maxSample = Math.max(...samplesArray);
          const absMax = Math.max(Math.abs(minSample), Math.abs(maxSample));
          if (absMax > globalMaxAmplitude) {
            globalMaxAmplitude = absMax;
            console.log(`[FishAudioTTS] ğŸ“Š Calibration chunk ${totalChunks}: range=[${minSample}, ${maxSample}], absMax=${absMax}, globalMax=${globalMaxAmplitude}`);
          }
        }
        
        // ã‚²ã‚¤ãƒ³ãƒ•ã‚¡ã‚¯ã‚¿ãƒ¼ã‚’æ±ºå®šï¼ˆæœ€åˆã®æ•°ãƒãƒ£ãƒ³ã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—å¾Œï¼‰
        if (totalChunks === GAIN_CALIBRATION_CHUNKS && gainFactor === null) {
          console.log(`[FishAudioTTS] ğŸ” Calibration complete: globalMaxAmplitude=${globalMaxAmplitude}, MIN_AMPLITUDE_THRESHOLD=${MIN_AMPLITUDE_THRESHOLD}`);
          if (globalMaxAmplitude > 0 && globalMaxAmplitude < MIN_AMPLITUDE_THRESHOLD) {
            // ä½æŒ¯å¹…ãŒæ¤œå‡ºã•ã‚ŒãŸå ´åˆã€çµ±ä¸€çš„ãªã‚²ã‚¤ãƒ³ã‚’è¨ˆç®—
            gainFactor = Math.min(
              MAX_GAIN_FACTOR,
              Math.floor((MIN_AMPLITUDE_THRESHOLD * 10) / globalMaxAmplitude)
            );
            console.log(`[FishAudioTTS] ğŸ”Š Global max amplitude: ${globalMaxAmplitude}, applying unified gain: ${gainFactor}x`);
          } else {
            // æ­£å¸¸ãªæŒ¯å¹…ç¯„å›²ã®å ´åˆã€ã‚²ã‚¤ãƒ³ã¯ä¸è¦
            gainFactor = 1;
            console.log(`[FishAudioTTS] âœ“ Normal amplitude detected (max: ${globalMaxAmplitude}), no gain needed`);
          }
        }
        
        // ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰ä¸€å®šã‚µã‚¤ã‚ºã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ã¦LiveKitã«é€ä¿¡
        // ãƒãƒƒãƒ•ã‚¡ã«ååˆ†ãªãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹é™ã‚Šã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’æŠ½å‡ºã—ç¶šã‘ã‚‹
        while (pcmBuffer.length >= TARGET_FRAME_SIZE) {
          // 1ãƒ•ãƒ¬ãƒ¼ãƒ åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡ºï¼ˆã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦å®‰å…¨ã«å‡¦ç†ï¼‰
          const frameData = Buffer.from(pcmBuffer.slice(0, TARGET_FRAME_SIZE)); // æ˜ç¤ºçš„ã«ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
          pcmBuffer = pcmBuffer.slice(TARGET_FRAME_SIZE);
          
          // Buffer ã‚’ Int16Array (PCM) ã«å¤‰æ›ï¼ˆã‚³ãƒ”ãƒ¼ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼‰
          const frameSamples = new Int16Array(
            frameData.buffer,
            frameData.byteOffset,
            frameData.length / 2,
          );
          
          // ãƒ•ãƒ¬ãƒ¼ãƒ ã®æŒ¯å¹…ã‚’ãƒã‚§ãƒƒã‚¯
          let frameAbsMax = 0;
          if (frameSamples.length > 0) {
            const samplesArray = Array.from(frameSamples);
            const minSample = Math.min(...samplesArray);
            const maxSample = Math.max(...samplesArray);
            frameAbsMax = Math.max(Math.abs(minSample), Math.abs(maxSample));
          }
          
          // éŸ³å£°é–‹å§‹å¾Œã®ä½æŒ¯å¹…ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—ï¼ˆæœ€åˆã®æ•°ãƒ•ãƒ¬ãƒ¼ãƒ ã®ã¿ï¼‰
          if (audioStarted && frameAbsMax < SILENCE_THRESHOLD && framesSkipped < MAX_SILENT_FRAMES_AFTER_START) {
            framesSkipped++;
            console.log(`[FishAudioTTS] â­ï¸ Skipping low amplitude frame ${framesSent + framesSkipped} after audio start (absMax=${frameAbsMax})`);
            continue; // ã“ã®ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—
          }
          
          // ã‚²ã‚¤ãƒ³ã‚’é©ç”¨ï¼ˆã‚²ã‚¤ãƒ³ãŒæ±ºå®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
          let pcmData: Int16Array;
          if (gainFactor !== null && gainFactor > 1) {
            const scaledSamples = new Int16Array(frameSamples.length);
            for (let i = 0; i < frameSamples.length; i++) {
              const scaled = frameSamples[i]! * gainFactor;
              // ã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã‚’é˜²æ­¢
              scaledSamples[i] = Math.max(-32767, Math.min(32767, scaled));
            }
            pcmData = scaledSamples;
          } else {
            // ã‚²ã‚¤ãƒ³ãŒã¾ã æ±ºå®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ã¾ãŸã¯ä¸è¦ãªå ´åˆ
            // Int16Arrayã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ãƒ¡ãƒ¢ãƒªã®å…±æœ‰ã‚’é¿ã‘ã‚‹
            pcmData = new Int16Array(frameSamples);
          }
          
          // LiveKit AudioFrame ã«å¤‰æ›
          const samplesPerChannel = pcmData.length / this.ttsInstance.numChannels;
          const audioFrame = new AudioFrame(
            pcmData,
            this.ttsInstance.sampleRate,
            this.ttsInstance.numChannels,
            samplesPerChannel,
          );
          
          // LiveKitã«é€ä¿¡ã™ã‚‹å‰ã«ã€å®Ÿéš›ã«é€ä¿¡ã•ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
          framesSent++;
          if (framesSent <= 10 || (framesSent > 15 && framesSent <= 30)) {
            // æœ€åˆã®10ãƒ•ãƒ¬ãƒ¼ãƒ ã¨æ­£å¸¸ãªæŒ¯å¹…ã®ãƒ•ãƒ¬ãƒ¼ãƒ ï¼ˆ15-30ï¼‰ã‚’ä¿å­˜
            const debugFrameFile = path.join(debugDateDir, `livekit-frame-${framesSent}.bin`);
            // AudioFrameã®ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ä¿å­˜ï¼ˆInt16Arrayå½¢å¼ï¼‰
            fs.writeFileSync(debugFrameFile, Buffer.from(pcmData.buffer, pcmData.byteOffset, pcmData.length * 2));
            console.log(`[FishAudioTTS] ğŸ” Saved LiveKit frame ${framesSent}: ${pcmData.length} samples, samplesPerChannel=${samplesPerChannel}, absMax=${frameAbsMax}`);
          }
          
          const audio = {
            requestId: '',
            segmentId: `segment-${segmentId++}`,
            frame: audioFrame,
            final: false, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã¯ false
          };
          this.queue.put(audio);
        }
      }
      
      // æœ€å¾Œã«ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆæœ€å°ã‚µã‚¤ã‚ºä»¥ä¸Šã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆï¼‰
      // æ³¨æ„: æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ã¯é€šå¸¸ã®ã‚µã‚¤ã‚ºã‚ˆã‚Šå°ã•ããªã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŒã€LiveKitã¯ã“ã‚Œã‚’å‡¦ç†ã§ãã‚‹
      if (pcmBuffer.length > 0) {
        const remainingSamples = pcmBuffer.length / 2;
        if (remainingSamples > 0) {
          // ãƒãƒƒãƒ•ã‚¡ã®æ®‹ã‚Šãƒ‡ãƒ¼ã‚¿ã‚’ã‚³ãƒ”ãƒ¼ã—ã¦å®‰å…¨ã«å‡¦ç†
          const remainingData = Buffer.from(pcmBuffer); // æ˜ç¤ºçš„ã«ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆ
          const frameSamples = new Int16Array(
            remainingData.buffer,
            remainingData.byteOffset,
            remainingSamples,
          );
          
          // ã‚²ã‚¤ãƒ³ã‚’é©ç”¨ï¼ˆã‚²ã‚¤ãƒ³ãŒæ±ºå®šã•ã‚Œã¦ã„ã‚‹å ´åˆï¼‰
          let pcmData: Int16Array;
          if (gainFactor !== null && gainFactor > 1) {
            const scaledSamples = new Int16Array(frameSamples.length);
            for (let i = 0; i < frameSamples.length; i++) {
              const scaled = frameSamples[i]! * gainFactor;
              scaledSamples[i] = Math.max(-32767, Math.min(32767, scaled));
            }
            pcmData = scaledSamples;
          } else {
            // ã‚²ã‚¤ãƒ³ãŒã¾ã æ±ºå®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ã¾ãŸã¯ä¸è¦ãªå ´åˆ
            // Int16Arrayã®ã‚³ãƒ”ãƒ¼ã‚’ä½œæˆã—ã¦ãƒ¡ãƒ¢ãƒªã®å…±æœ‰ã‚’é¿ã‘ã‚‹
            pcmData = new Int16Array(frameSamples);
          }
          
          // LiveKit AudioFrame ã«å¤‰æ›
          const samplesPerChannel = pcmData.length / this.ttsInstance.numChannels;
          const audioFrame = new AudioFrame(
            pcmData,
            this.ttsInstance.sampleRate,
            this.ttsInstance.numChannels,
            samplesPerChannel,
          );
          
          framesSent++;
          const audio = {
            requestId: '',
            segmentId: `segment-${segmentId++}`,
            frame: audioFrame,
            final: true, // æœ€å¾Œã®ãƒ•ãƒ¬ãƒ¼ãƒ ãªã®ã§ final=true
          };
          this.queue.put(audio);
          console.log(`[FishAudioTTS] ğŸ” Flushed final frame: ${pcmData.length} samples, samplesPerChannel=${samplesPerChannel}`);
        }
      }
      
      // å…¨ãƒãƒ£ãƒ³ã‚¯å—ä¿¡å®Œäº†æ™‚ã®å‡¦ç†æ™‚é–“ã‚µãƒãƒªãƒ¼
      const allChunksReceivedTime = Date.now();
      const totalProcessingTime = allChunksReceivedTime - sessionStartTime;
      const httpRequestToCompletionTime = allChunksReceivedTime - httpRequestStartTime;
      const totalAudioBytes = allChunksForLogging.reduce((sum, chunk) => sum + chunk.length, 0);
      
      console.log('='.repeat(80));
      console.log('[TTS Processing Summary]');
      const ttsSummary = {
        textReceiveDuration: `${textReceiveDuration}ms`,
        httpRequestToFirstChunk: firstChunkReceived ? `${firstChunkTimeFromHttpRequest}ms` : 'N/A',
        httpRequestToCompletion: `${httpRequestToCompletionTime}ms`,
        totalProcessingTime: `${totalProcessingTime}ms`,
        totalChunksReceived: totalChunks,
        totalAudioDataBytes: totalAudioBytes,
        totalAudioDataKB: `${(totalAudioBytes / 1024).toFixed(2)} KB`,
        framesSentToLiveKit: framesSent,
        framesSkipped: framesSkipped,
      };
      console.log(`Text receive duration: ${ttsSummary.textReceiveDuration}`);
      console.log(`HTTP request to first chunk: ${ttsSummary.httpRequestToFirstChunk}`);
      console.log(`HTTP request to completion: ${ttsSummary.httpRequestToCompletion}`);
      console.log(`Total processing time: ${ttsSummary.totalProcessingTime}`);
      console.log(`Total chunks received: ${ttsSummary.totalChunksReceived}`);
      console.log(`Total audio data: ${ttsSummary.totalAudioDataBytes} bytes (${ttsSummary.totalAudioDataKB})`);
      console.log(`Frames sent to LiveKit: ${ttsSummary.framesSentToLiveKit}`);
      console.log(`Frames skipped: ${ttsSummary.framesSkipped}`);
      console.log('='.repeat(80));
      
      // TTSå‡¦ç†æ™‚é–“ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
      const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
      const ttsLogFile = path.join(debugDateDir, `tts-processing-times-${timestamp}.json`);
      fs.writeFileSync(ttsLogFile, JSON.stringify(ttsSummary, null, 2));
      console.log(`[FishAudioTTS] ğŸ’¾ Saved TTS processing times log to: ${ttsLogFile}`);
      
      const totalTime = Date.now() - sessionStartTime;
      
      // å…¨ã¦ã®ãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã—ã¦ä¿å­˜ï¼ˆãƒ­ã‚°ç”¨ï¼‰
      if (allChunksForLogging.length > 0) {
        const allChunksCombined = Buffer.concat(allChunksForLogging);
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const fullAudioFile = path.join(debugDateDir, `full-audio-${timestamp}-${totalChunks}chunks.bin`);
        fs.writeFileSync(fullAudioFile, allChunksCombined);
        console.log(`[FishAudioTTS] ğŸ’¾ Saved all ${allChunksForLogging.length} chunks (${allChunksCombined.length} bytes) to: ${fullAudioFile}`);
        
        // WAVãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ã‚‚ä¿å­˜ï¼ˆå†ç”Ÿå¯èƒ½ãªå½¢å¼ï¼‰
        const samples = new Int16Array(allChunksCombined.buffer, allChunksCombined.byteOffset, allChunksCombined.length / 2);
        const sampleRate = this.ttsInstance.sampleRate;
        const numChannels = this.ttsInstance.numChannels;
        const bitsPerSample = 16;
        const dataSize = allChunksCombined.length;
        const fileSize = 36 + dataSize;
        
        const wavHeader = Buffer.alloc(44);
        wavHeader.write('RIFF', 0);
        wavHeader.writeUInt32LE(fileSize, 4);
        wavHeader.write('WAVE', 8);
        wavHeader.write('fmt ', 12);
        wavHeader.writeUInt32LE(16, 16);
        wavHeader.writeUInt16LE(1, 20);
        wavHeader.writeUInt16LE(numChannels, 22);
        wavHeader.writeUInt32LE(sampleRate, 24);
        wavHeader.writeUInt32LE(sampleRate * numChannels * (bitsPerSample / 8), 28);
        wavHeader.writeUInt16LE(numChannels * (bitsPerSample / 8), 32);
        wavHeader.writeUInt16LE(bitsPerSample, 34);
        wavHeader.write('data', 36);
        wavHeader.writeUInt32LE(dataSize, 40);
        
        const wavFile = path.join(debugDateDir, `full-audio-${timestamp}-${totalChunks}chunks.wav`);
        const wavData = Buffer.concat([wavHeader, allChunksCombined]);
        fs.writeFileSync(wavFile, wavData);
        console.log(`[FishAudioTTS] ğŸ’¾ Saved full audio as WAV (${(samples.length / sampleRate).toFixed(3)}s) to: ${wavFile}`);
      }
      
      // ä¿å­˜ã—ãŸãƒãƒ£ãƒ³ã‚¯ã‚’çµåˆã—ã¦è©³ç´°åˆ†æ
      if (allChunksForAnalysis.length > 0) {
        const combinedData = Buffer.concat(allChunksForAnalysis);
        console.log(`[FishAudioTTS] ğŸ” Analyzing ${allChunksForAnalysis.length} chunks (${combinedData.length} bytes total)`);
        
        // çµåˆã—ãŸãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ã‚’åˆ¤å®š
        const combinedFormat = detectAudioFormat(combinedData);
        console.log(`[FishAudioTTS] ğŸ” Combined data format: ${combinedFormat}`);
        
        // ãƒã‚¤ãƒŠãƒªãƒ‡ãƒ¼ã‚¿ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
        const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
        const debugFile = path.join(debugDateDir, `fish-audio-${timestamp}-${totalChunks}chunks.bin`);
        fs.writeFileSync(debugFile, combinedData);
        console.log(`[FishAudioTTS] ğŸ’¾ Saved first ${allChunksForAnalysis.length} chunks to: ${debugFile}`);
        console.log(`[FishAudioTTS] ğŸ’¾ File size: ${combinedData.length} bytes`);
        console.log(`[FishAudioTTS] ğŸ’¾ To analyze: file ${debugFile} | xxd | head -20`);
        
        // ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’å‡ºåŠ›
        const byteCounts = new Array(256).fill(0);
        const sampleSize = Math.min(1000, combinedData.length);
        for (let i = 0; i < sampleSize; i++) {
          byteCounts[combinedData[i]!]++;
        }
        const mostCommonBytes = byteCounts
          .map((count, byte) => ({ byte, count }))
          .sort((a, b) => b.count - a.count)
          .slice(0, 5);
        console.log(`[FishAudioTTS] ğŸ“Š Most common bytes in first ${sampleSize} bytes:`, 
          mostCommonBytes.map(({ byte, count }) => `0x${byte.toString(16).padStart(2, '0').toUpperCase()}:${count}`).join(', '));
      }
      
      console.log('[FishAudioTTS] HTTP API streaming synthesis session completed');
    } catch (error) {
      console.error('[FishAudioTTS] HTTP API streaming error:', error);
      // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
      if (error instanceof Error) {
        console.error('[FishAudioTTS] Error name:', error.name);
        console.error('[FishAudioTTS] Error message:', error.message);
        console.error('[FishAudioTTS] Error stack:', error.stack);
        if ('code' in error) {
          console.error('[FishAudioTTS] Error code:', (error as any).code);
        }
        if ('details' in error) {
          console.error('[FishAudioTTS] Error details:', (error as any).details);
        }
      }
      console.error('[FishAudioTTS] Backend used:', this.ttsInstance.backend);
      console.error('[FishAudioTTS] Voice ID:', this.ttsInstance.voiceId);
      throw error;
    }
  }

}

