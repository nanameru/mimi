import { tts } from '@livekit/agents';
import { AudioFrame } from '@livekit/rtc-node';
import { Session, TTSRequest, type Backends } from 'fish-audio-sdk';

/**
 * Fish Audio TTS è¨­å®š
 * å…¬å¼ fish-audio-sdk ã‚’ä½¿ç”¨ã—ãŸé«˜å“è³ªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°åˆæˆ
 * HTTP APIã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
 * æ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã®æœ€é©åŒ–ã‚’å®Ÿè£…
 * ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ: https://docs.fish.audio/api-reference/introduction
 * npm: https://www.npmjs.com/package/fish-audio-sdk
 */
export interface FishAudioTTSOptions {
  apiKey?: string;
  voiceId?: string;
  sampleRate?: number;
  numChannels?: number;
  backend?: Backends;
  chunkLength?: number;
  latency?: 'normal' | 'balanced';
}


/**
 * Fish Audio TTS å®Ÿè£…
 * HTTP APIã‚’ä½¿ç”¨ã—ã¦ã‚¨ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³ã‚¿ã‚°ã‚’ã‚µãƒãƒ¼ãƒˆ
 * æ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°ã¨HTTP/2ã®æœ€é©åŒ–ã‚’å®Ÿè£…
 */
export class FishAudioTTS extends tts.TTS {
  label = 'fish-audio-tts';
  public apiKey: string;
  public voiceId: string;
  public backend: Backends;
  public chunkLength: number;
  public latency: 'normal' | 'balanced';
  public httpSession: Session;

  constructor(options: FishAudioTTSOptions = {}) {
    const sampleRate = options.sampleRate || 44100;
    const numChannels = options.numChannels || 1;
    // TTS capabilities ã‚’è¨­å®šï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰
    super(sampleRate, numChannels, {
      streaming: true,
    });
    this.apiKey = options.apiKey || process.env.FISH_AUDIO_API_KEY || '';
    this.voiceId = options.voiceId || process.env.FISH_AUDIO_VOICE_ID || '';
    this.backend = options.backend || 'speech-1.5';
    this.chunkLength = options.chunkLength || 100;
    this.latency = options.latency || 'balanced';
    if (!this.apiKey) {
      throw new Error('FISH_AUDIO_API_KEY is required');
    }
    // HTTP Session ã‚’åˆæœŸåŒ–ï¼ˆæ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–ï¼‰
    // fish-audio-sdkã®Sessionã‚¯ãƒ©ã‚¹ã¯æ—¢ã«keepAliveã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ãŸã‚ã€
    // åŸºæœ¬çš„ãªæ¥ç¶šãƒ—ãƒ¼ãƒªãƒ³ã‚°æœ€é©åŒ–ã¯è¡Œã‚ã‚Œã¦ã„ã¾ã™
    // ã‚ˆã‚Šè©³ç´°ãªæœ€é©åŒ–ï¼ˆmaxSockets, maxFreeSocketsãªã©ï¼‰ãŒå¿…è¦ãªå ´åˆã¯ã€
    // fish-audio-sdkã®ã‚½ãƒ¼ã‚¹ã‚³ãƒ¼ãƒ‰ã‚’ä¿®æ­£ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™
    // HTTP/2ã®ã‚µãƒãƒ¼ãƒˆã«ã¤ã„ã¦ã¯ã€Fish Audio APIãŒã‚µãƒãƒ¼ãƒˆã—ã¦ã„ã‚‹ã‹ç¢ºèªãŒå¿…è¦ã§ã™
    this.httpSession = new Session(this.apiKey);
    console.log(
      `[FishAudioTTS] Initialized with HTTP API: backend=${this.backend}, voiceId=${this.voiceId ? 'set' : 'not set'}, sampleRate=${sampleRate}Hz, channels=${numChannels}`,
    );
    console.log('[FishAudioTTS] Connection pooling: keepAlive=true (fish-audio-sdk default)');
  }

  /**
   * ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’åˆæˆï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ï¼‰
   */
  synthesize(text: string): tts.ChunkedStream {
    console.log(`[FishAudioTTS] Synthesizing text (length=${text.length})`);
    return new FishAudioChunkedStream(text, this);
  }

  /**
   * ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° TTS
   */
  stream(): tts.SynthesizeStream {
    console.log('[FishAudioTTS] Creating streaming session');
    return new FishAudioSynthesizeStream(this);
  }

  /**
   * ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
   */
  async close(): Promise<void> {
    this.httpSession.close();
    console.log('[FishAudioTTS] HTTP session closed');
  }
}

/**
 * Fish Audio ãƒãƒ£ãƒ³ã‚¯ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆéã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°åˆæˆç”¨ï¼‰
 */
class FishAudioChunkedStream extends tts.ChunkedStream {
  label = 'fish-audio-chunked-stream';
  private text: string;
  private ttsInstance: FishAudioTTS;

  constructor(text: string, ttsInstance: FishAudioTTS) {
    super(text, ttsInstance);
    this.text = text;
    this.ttsInstance = ttsInstance;
  }

  async run() {
    try {
      console.log('[FishAudioTTS] Starting non-streaming synthesis');
      // TTSRequest ã‚’ä½œæˆï¼ˆãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚ã‚‹ï¼‰
      const request = new TTSRequest(this.text, {
        referenceId: this.ttsInstance.voiceId,
        format: 'pcm',
        sampleRate: this.ttsInstance.sampleRate,
        chunkLength: this.ttsInstance.chunkLength,
        latency: this.ttsInstance.latency,
        normalize: true,
      });
      // HTTP APIã§éŸ³å£°ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰
      // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦modelãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
      const audioChunks: Buffer[] = [];
      let firstChunkForSynthesize = true;
      for await (const chunk of this.ttsInstance.httpSession.tts(request, {
        model: this.ttsInstance.backend,
      })) {
        // æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®å…ˆé ­ãƒã‚¤ãƒˆã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šç”¨ï¼‰
        if (firstChunkForSynthesize) {
          const firstChunkPreview = chunk.slice(0, Math.min(32, chunk.length));
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (hex): ${firstChunkPreview.toString('hex')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk length: ${chunk.length} bytes`);
          
          // MP3ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ç¢ºèª
          const firstBytes = chunk.slice(0, 4);
          const hexString = firstBytes.toString('hex').toUpperCase();
          if (hexString.startsWith('FF')) {
            console.log(`[FishAudioTTS] âš ï¸ WARNING: First bytes suggest MP3 format (${hexString}), but PCM format was requested!`);
            console.log(`[FishAudioTTS] âš ï¸ This may cause audio quality issues. MP3 decoding may be required.`);
          } else {
            console.log(`[FishAudioTTS] âœ“ First bytes suggest PCM format (${hexString})`);
            
            // PCMãƒ‡ãƒ¼ã‚¿ã®è©³ç´°ç¢ºèª
            if (chunk.length >= 2) {
              const firstSampleLE = chunk.readInt16LE(0);
              const firstSampleBE = chunk.readInt16BE(0);
              console.log(`[FishAudioTTS] ğŸ“Š First sample (Little Endian): ${firstSampleLE}`);
              console.log(`[FishAudioTTS] ğŸ“Š First sample (Big Endian): ${firstSampleBE}`);
            }
          }
          firstChunkForSynthesize = false;
        }
        audioChunks.push(chunk);
      }
      // éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
      const audioBuffer = Buffer.concat(audioChunks);
      console.log(`[FishAudioTTS] Received ${audioBuffer.length} bytes of audio`);
      // LiveKit AudioFrame ã«å¤‰æ›
      const pcmData = new Int16Array(
        audioBuffer.buffer,
        audioBuffer.byteOffset,
        audioBuffer.length / 2,
      );
      const samplesPerChannel = pcmData.length / this.ttsInstance.numChannels;
      const audioFrame = new AudioFrame(
        pcmData,
        this.ttsInstance.sampleRate,
        this.ttsInstance.numChannels,
        samplesPerChannel,
      );
      const audio = {
        requestId: '',
        segmentId: 'segment-0',
        frame: audioFrame,
        final: true,
      };
      this.queue.put(audio);
      console.log('[FishAudioTTS] Synthesis completed');
    } catch (error) {
      console.error('[FishAudioTTS] Error:', error);
      throw error;
    }
  }
}

/**
 * Fish Audio ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Ÿè£…
 * LLM ã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã§éŸ³å£°ã«å¤‰æ›
 */
class FishAudioSynthesizeStream extends tts.SynthesizeStream {
  label = 'fish-audio-synthesize-stream';
  private ttsInstance: FishAudioTTS;

  constructor(ttsInstance: FishAudioTTS) {
    super(ttsInstance);
    this.ttsInstance = ttsInstance;
  }

  async run() {
    try {
      const sessionStartTime = Date.now();
      console.log(
        `[FishAudioTTS] [${new Date().toLocaleTimeString()}] Starting HTTP API streaming synthesis session`,
      );
      
      // LLMã‹ã‚‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’å®Œå…¨ã«å—ä¿¡
      const textBuffer: string[] = [];
      for await (const text of this.input) {
        if (text === FishAudioSynthesizeStream.FLUSH_SENTINEL) {
          // FLUSH_SENTINELãŒæ¥ãŸã‚‰ã€ãƒãƒƒãƒ•ã‚¡ã«æ®‹ã£ã¦ã„ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡
          if (textBuffer.length > 0) {
            break; // ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã¦HTTP APIã«é€ä¿¡
          }
          continue;
        }
        textBuffer.push(text);
      }
      
      // ãƒ†ã‚­ã‚¹ãƒˆã‚’çµåˆ
      const fullText = textBuffer.join('');
      console.log(
        `[FishAudioTTS] ğŸ“¤ [${new Date().toLocaleTimeString()}] Sending text to HTTP API (${fullText.length} chars): "${fullText.substring(0, 50)}..."`,
      );
      
      // HTTP APIã§éŸ³å£°ç”Ÿæˆï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ï¼‰
      // ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã«åŸºã¥ã„ã¦modelãƒ˜ãƒƒãƒ€ãƒ¼ã‚’è¿½åŠ 
      const request = new TTSRequest(fullText, {
        referenceId: this.ttsInstance.voiceId,
        format: 'pcm',
        sampleRate: this.ttsInstance.sampleRate,
        chunkLength: this.ttsInstance.chunkLength,
        latency: this.ttsInstance.latency,
        normalize: true,
      });
      
      let segmentId = 0;
      let firstChunkReceived = false;
      let totalChunks = 0;
      console.log(`[FishAudioTTS] Starting HTTP API TTS with backend: ${this.ttsInstance.backend}, voiceId: ${this.ttsInstance.voiceId || 'not set'}`);
      
      // HTTP APIã¯ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’è¿”ã™
      for await (const audioChunk of this.ttsInstance.httpSession.tts(request, {
        model: this.ttsInstance.backend,
      })) {
        totalChunks++;
        // æœ€åˆã®éŸ³å£°ãƒãƒ£ãƒ³ã‚¯å—ä¿¡æ™‚ã®ãƒ­ã‚°
        if (!firstChunkReceived) {
          const firstChunkTime = Date.now() - sessionStartTime;
          console.log(
            `[FishAudioTTS] â±ï¸ First audio chunk received after ${firstChunkTime}ms`,
          );
          // æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®å…ˆé ­ãƒã‚¤ãƒˆã‚’ç¢ºèªï¼ˆãƒ‡ãƒ¼ã‚¿å½¢å¼ã®åˆ¤å®šç”¨ï¼‰
          const firstChunkPreview = audioChunk.slice(0, Math.min(32, audioChunk.length));
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (hex): ${firstChunkPreview.toString('hex')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk preview (decimal): ${Array.from(firstChunkPreview).join(', ')}`);
          console.log(`[FishAudioTTS] ğŸ” First chunk length: ${audioChunk.length} bytes`);
          
          // MP3ã®ãƒã‚¸ãƒƒã‚¯ãƒŠãƒ³ãƒãƒ¼ã‚’ç¢ºèªï¼ˆFF FB, FF F3, FF F2, FF FAãªã©ï¼‰
          const firstBytes = audioChunk.slice(0, 4);
          const hexString = firstBytes.toString('hex').toUpperCase();
          if (hexString.startsWith('FF')) {
            console.log(`[FishAudioTTS] âš ï¸ WARNING: First bytes suggest MP3 format (${hexString}), but PCM format was requested!`);
            console.log(`[FishAudioTTS] âš ï¸ This may cause audio quality issues. MP3 decoding may be required.`);
          } else {
            console.log(`[FishAudioTTS] âœ“ First bytes suggest PCM format (${hexString})`);
          }
          
          // PCMãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆæƒ…å ±ã‚’ç¢ºèª
          if (audioChunk.length >= 2) {
            const sampleCount = audioChunk.length / 2;
            console.log(`[FishAudioTTS] ğŸ“Š Estimated sample count: ${sampleCount} (assuming 16-bit PCM)`);
            console.log(`[FishAudioTTS] ğŸ“Š Estimated duration: ${(sampleCount / this.ttsInstance.sampleRate * 1000).toFixed(2)}ms`);
            
            // å®Ÿéš›ã®PCMãƒ‡ãƒ¼ã‚¿ã®å€¤ã‚’ç¢ºèªï¼ˆæœ€åˆã®10ã‚µãƒ³ãƒ—ãƒ«ï¼‰
            const pcmSamples = new Int16Array(
              audioChunk.buffer,
              audioChunk.byteOffset,
              Math.min(10, audioChunk.length / 2),
            );
            console.log(`[FishAudioTTS] ğŸ“Š First 10 PCM samples (Int16): [${Array.from(pcmSamples).join(', ')}]`);
            
            // ãƒªãƒˆãƒ«ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã¨ãƒ“ãƒƒã‚°ã‚¨ãƒ³ãƒ‡ã‚£ã‚¢ãƒ³ã®ä¸¡æ–¹ã‚’ç¢ºèª
            const firstSampleLE = audioChunk.readInt16LE(0);
            const firstSampleBE = audioChunk.readInt16BE(0);
            console.log(`[FishAudioTTS] ğŸ“Š First sample (Little Endian): ${firstSampleLE}`);
            console.log(`[FishAudioTTS] ğŸ“Š First sample (Big Endian): ${firstSampleBE}`);
            
            // ãƒ‡ãƒ¼ã‚¿ã®ç¯„å›²ã‚’ç¢ºèªï¼ˆã‚¯ãƒªãƒƒãƒ”ãƒ³ã‚°ã®å¯èƒ½æ€§ã‚’ãƒã‚§ãƒƒã‚¯ï¼‰
            const allSamples = new Int16Array(
              audioChunk.buffer,
              audioChunk.byteOffset,
              audioChunk.length / 2,
            );
            if (allSamples.length > 0) {
              const samplesArray = Array.from(allSamples);
              const minSample = Math.min(...samplesArray);
              const maxSample = Math.max(...samplesArray);
              console.log(`[FishAudioTTS] ğŸ“Š Sample range: [${minSample}, ${maxSample}] (Int16 range: [-32768, 32767])`);
              
              // ã‚¼ãƒ­ã‚¯ãƒ­ãƒƒã‚·ãƒ³ã‚°ã®é »åº¦ã‚’ç¢ºèªï¼ˆæ­£å¸¸ãªéŸ³å£°ãƒ‡ãƒ¼ã‚¿ãªã‚‰é©åº¦ãªã‚¼ãƒ­ã‚¯ãƒ­ãƒƒã‚·ãƒ³ã‚°ãŒã‚ã‚‹ï¼‰
              let zeroCrossings = 0;
              for (let i = 1; i < allSamples.length; i++) {
                const prevSample = allSamples[i - 1]!;
                const currSample = allSamples[i]!;
                if ((prevSample >= 0 && currSample < 0) || (prevSample < 0 && currSample >= 0)) {
                  zeroCrossings++;
                }
              }
              console.log(`[FishAudioTTS] ğŸ“Š Zero crossings: ${zeroCrossings} (${((zeroCrossings / allSamples.length) * 100).toFixed(2)}%)`);
              
              // ç•°å¸¸ãªãƒ‡ãƒ¼ã‚¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œå‡º
              if (Math.abs(minSample) > 32767 || Math.abs(maxSample) > 32767) {
                console.log(`[FishAudioTTS] âš ï¸ WARNING: Sample values exceed Int16 range!`);
              }
              if (zeroCrossings === 0) {
                console.log(`[FishAudioTTS] âš ï¸ WARNING: No zero crossings detected - data may be corrupted or DC offset`);
              }
            }
          }
          
          firstChunkReceived = true;
        }
        // Buffer ã‚’ Int16Array (PCM) ã«å¤‰æ›
        const pcmData = new Int16Array(
          audioChunk.buffer,
          audioChunk.byteOffset,
          audioChunk.length / 2,
        );
        // LiveKit AudioFrame ã«å¤‰æ›
        const samplesPerChannel = pcmData.length / this.ttsInstance.numChannels;
        const audioFrame = new AudioFrame(
          pcmData,
          this.ttsInstance.sampleRate,
          this.ttsInstance.numChannels,
          samplesPerChannel,
        );
        const audio = {
          requestId: '',
          segmentId: `segment-${segmentId++}`,
          frame: audioFrame,
          final: false, // ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã¯ false
        };
        this.queue.put(audio);
      }
      
      const totalTime = Date.now() - sessionStartTime;
      console.log(
        `[FishAudioTTS] â±ï¸ Total audio generation: ${totalTime}ms (${totalChunks} chunks)`,
      );
      console.log('[FishAudioTTS] HTTP API streaming synthesis session completed');
    } catch (error) {
      console.error('[FishAudioTTS] HTTP API streaming error:', error);
      // ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã‚’ãƒ­ã‚°ã«å‡ºåŠ›
      if (error instanceof Error) {
        console.error('[FishAudioTTS] Error name:', error.name);
        console.error('[FishAudioTTS] Error message:', error.message);
        console.error('[FishAudioTTS] Error stack:', error.stack);
        if ('code' in error) {
          console.error('[FishAudioTTS] Error code:', (error as any).code);
        }
        if ('details' in error) {
          console.error('[FishAudioTTS] Error details:', (error as any).details);
        }
      }
      console.error('[FishAudioTTS] Backend used:', this.ttsInstance.backend);
      console.error('[FishAudioTTS] Voice ID:', this.ttsInstance.voiceId);
      throw error;
    }
  }

}

